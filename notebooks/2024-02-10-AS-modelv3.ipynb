{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/zindi_llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import torch\n",
    "from utils.embeddings import Embedder\n",
    "from utils.preprocess import create_sentance_booklet, create_faise_index\n",
    "import faiss\n",
    "from utils.utils import search_content, read_booklets, retrieve_booklet_text, clean_text\n",
    "from models.llama import llama_cpp\n",
    "from utils.response_generator import get_response, extract_keyword\n",
    "from rouge_score import rouge_scorer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silly Mac that forces me to change the environmental variable to prevent issues running transformers\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd  = str(pathlib.Path().cwd().parent.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet = read_booklets((pwd + \"/data/data/booklets/\"))\n",
    "df_train = pd.read_csv(pwd + \"/data/data/Train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Clean some of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet['cleanText'] = df_booklet['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet['numWords'] = [len(text.split(\" \")) for text in df_booklet['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet_clean = df_booklet[df_booklet['numWords']< 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There paragraphs are long, so we might need to consider spliting text on sentences to make them shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem like the following steps will have to be taken:\n",
    "\n",
    "- embed booklet\n",
    "- embed search phrase\n",
    "- use search phrase embedding to search for relevant text in booklet\n",
    "- retrive all relevant text from booklet\n",
    "- format search phrase and into prompt for LLM\n",
    "- Send promt to LLM and return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try simple model\n",
    "I will first use all-mpnet-base-v2  as the sentance embedder and then I will use phi2 as the LLM .\n",
    "\n",
    "- Download: huggingface-cli download TheBloke/Llama-2-7b-Chat-GGUF llama-2-7b-chat.Q5_K_M.gguf --local-dir . --local-dir-use-symlinks False\n",
    "\n",
    "- Then run: pip install llama-cpp-python==0.2.39\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Embed all sentances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Embedder(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not create embeddings uncomment below\n",
    "# booklet_embeddings = embedding_model.embed(df_booklet_clean['cleanText'].values)\n",
    "#  np.save(file=(pwd + \"/data/data/resources/embeddings_cleanv3\" ), arr=booklet_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index train answers\n",
    "# train_embeddings = embedding_model.embed(df_train['Question Answer'].values)\n",
    "# np.save(file=(pwd + \"/data/data/resources/embeddings_train\" ), arr=train_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creat faiss index for search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not create the index uncomment below\n",
    "# fastIndex = create_faise_index(booklet_embeddings)\n",
    "\n",
    "# # Save the index\n",
    "# faiss.write_index(fastIndex, pwd + \"/data/data/resources/paragraph_index_cleanv3.faiss\")\n",
    "# df_booklet_clean.to_csv(pwd + \"/data/data/resources/bookletv3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not create the index uncomment below\n",
    "# create index fro train\n",
    "# fastIndex_train = create_faise_index(train_embeddings)\n",
    "\n",
    "# # Save the index\n",
    "# faiss.write_index(fastIndex_train, pwd + \"/data/data/resources/train_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in index\n",
    "fastIndex = faiss.read_index( pwd + \"/data/data/resources/paragraph_index_cleanv3.faiss\")\n",
    "fastIndex_train = faiss.read_index( pwd + \"/data/data/resources/train_index.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Search embeddings and get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/altasaunders/Alta_projects/zindi_llm/llama-2-7b-chat.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 4.45 GiB (5.68 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4474.93 MiB, ( 4475.00 / 10922.67)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      Metal buffer size =  4474.93 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/opt/miniconda3/envs/zindi_llm/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1024.00 MiB, ( 5500.59 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    12.01 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.00 MiB, ( 5500.61 / 10922.67)\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   171.61 MiB, ( 5672.20 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =   171.60 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     8.80 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 3\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '17', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'LLaMA v2'}\n"
     ]
    }
   ],
   "source": [
    "llm_model = llama_cpp(pwd + \"/llama-2-7b-chat.Q5_K_M.gguf\", gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if you want to test on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(pwd +  \"/data/data/Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# rouge_scores = []\n",
    "# for question in df_train.head(1)['Question Text'].values.tolist():\n",
    "#     print(\"start\")\n",
    "#     df_search_results = search_content(query=question, df_sentances=df_booklet, index=fastIndex, embedder=embedding_model, k=5)\n",
    "#     response = get_response(text=question, llm=llm_model, df_matches=df_search_results)\n",
    "#     response[\"keywords\"] = extract_keyword(str(df_search_results['text'].values), top_n=6)\n",
    "#     scores = scorer.score(response['answer'], question)\n",
    "#     rouge_scores.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rouge_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(pwd +  \"/data/data/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      32.15 ms /   118 runs   (    0.27 ms per token,  3670.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     527.33 ms /    11 tokens (   47.94 ms per token,    20.86 tokens per second)\n",
      "llama_print_timings:        eval time =   10666.92 ms /   117 runs   (   91.17 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =   11878.56 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     1 runs   (    0.33 ms per token,  3067.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17275.79 ms /  1742 tokens (    9.92 ms per token,   100.83 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   17309.25 ms /  1743 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /     5 runs   (    0.33 ms per token,  3056.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12054.18 ms /  1248 tokens (    9.66 ms per token,   103.53 tokens per second)\n",
      "llama_print_timings:        eval time =     411.13 ms /     4 runs   (  102.78 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =   12528.97 ms /  1252 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     170.16 ms /   502 runs   (    0.34 ms per token,  2950.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     317.17 ms /    11 tokens (   28.83 ms per token,    34.68 tokens per second)\n",
      "llama_print_timings:        eval time =   45324.77 ms /   501 runs   (   90.47 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =   50430.77 ms /   512 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     1 runs   (    0.33 ms per token,  3003.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13317.12 ms /  1354 tokens (    9.84 ms per token,   101.67 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   13341.60 ms /  1355 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     225.69 ms /   662 runs   (    0.34 ms per token,  2933.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.80 ms /    15 tokens (   21.32 ms per token,    46.90 tokens per second)\n",
      "llama_print_timings:        eval time =   60363.79 ms /   661 runs   (   91.32 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =   67098.82 ms /   676 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     2 runs   (    0.35 ms per token,  2832.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17149.76 ms /  1742 tokens (    9.84 ms per token,   101.58 tokens per second)\n",
      "llama_print_timings:        eval time =     108.22 ms /     1 runs   (  108.22 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =   17298.24 ms /  1743 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     2 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6399.92 ms /   654 tokens (    9.79 ms per token,   102.19 tokens per second)\n",
      "llama_print_timings:        eval time =      95.47 ms /     1 runs   (   95.47 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =    6518.77 ms /   655 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     239.83 ms /   751 runs   (    0.32 ms per token,  3131.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12032.73 ms /  1237 tokens (    9.73 ms per token,   102.80 tokens per second)\n",
      "llama_print_timings:        eval time =   81355.75 ms /   750 runs   (  108.47 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =  101133.99 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     356.93 ms /   883 runs   (    0.40 ms per token,  2473.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3015.68 ms /   297 tokens (   10.15 ms per token,    98.49 tokens per second)\n",
      "llama_print_timings:        eval time =   85811.64 ms /   882 runs   (   97.29 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:       total time =   99187.85 ms /  1179 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     502.08 ms /  1000 runs   (    0.50 ms per token,  1991.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5363.32 ms /   532 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =  105091.69 ms /   999 runs   (  105.20 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =  124566.40 ms /  1531 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      36.48 ms /    54 runs   (    0.68 ms per token,  1480.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     329.02 ms /    18 tokens (   18.28 ms per token,    54.71 tokens per second)\n",
      "llama_print_timings:        eval time =    4835.44 ms /    53 runs   (   91.23 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =    5808.65 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     112.46 ms /   205 runs   (    0.55 ms per token,  1822.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4025.06 ms /   393 tokens (   10.24 ms per token,    97.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19313.93 ms /   204 runs   (   94.68 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =   25954.36 ms /   597 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     118.30 ms /   217 runs   (    0.55 ms per token,  1834.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17873.42 ms /  1771 tokens (   10.09 ms per token,    99.09 tokens per second)\n",
      "llama_print_timings:        eval time =   24435.18 ms /   216 runs   (  113.13 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =   45229.41 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     170.34 ms /   287 runs   (    0.59 ms per token,  1684.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     317.57 ms /     6 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   25883.28 ms /   286 runs   (   90.50 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =   30057.67 ms /   292 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     324.29 ms /   562 runs   (    0.58 ms per token,  1733.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14555.19 ms /  1485 tokens (    9.80 ms per token,   102.03 tokens per second)\n",
      "llama_print_timings:        eval time =   60500.22 ms /   561 runs   (  107.84 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =   83984.03 ms /  2046 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     223.34 ms /   403 runs   (    0.55 ms per token,  1804.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2066.42 ms /   205 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =   37951.43 ms /   402 runs   (   94.41 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =   45581.72 ms /   607 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     100.18 ms /   186 runs   (    0.54 ms per token,  1856.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8960.56 ms /   860 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19365.37 ms /   185 runs   (  104.68 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =   30710.14 ms /  1045 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     161.61 ms /   287 runs   (    0.56 ms per token,  1775.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     324.08 ms /    10 tokens (   32.41 ms per token,    30.86 tokens per second)\n",
      "llama_print_timings:        eval time =   27118.16 ms /   286 runs   (   94.82 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =   31029.26 ms /   296 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     351.93 ms /   668 runs   (    0.53 ms per token,  1898.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14278.23 ms /  1379 tokens (   10.35 ms per token,    96.58 tokens per second)\n",
      "llama_print_timings:        eval time =   72641.15 ms /   667 runs   (  108.91 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =   96546.37 ms /  2046 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      96.31 ms /   182 runs   (    0.53 ms per token,  1889.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13769.09 ms /  1389 tokens (    9.91 ms per token,   100.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19387.33 ms /   181 runs   (  107.11 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =   35569.58 ms /  1570 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      69.56 ms /   104 runs   (    0.67 ms per token,  1495.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     338.27 ms /    28 tokens (   12.08 ms per token,    82.77 tokens per second)\n",
      "llama_print_timings:        eval time =    9259.94 ms /   103 runs   (   89.90 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =   10896.45 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     150.83 ms /   303 runs   (    0.50 ms per token,  2008.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4276.33 ms /   417 tokens (   10.25 ms per token,    97.51 tokens per second)\n",
      "llama_print_timings:        eval time =   29419.16 ms /   302 runs   (   97.41 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =   37301.12 ms /   719 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      79.12 ms /   155 runs   (    0.51 ms per token,  1958.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7994.39 ms /   827 tokens (    9.67 ms per token,   103.45 tokens per second)\n",
      "llama_print_timings:        eval time =   15460.92 ms /   154 runs   (  100.40 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =   25362.07 ms /   981 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     344.14 ms /   714 runs   (    0.48 ms per token,  2074.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12433.10 ms /  1274 tokens (    9.76 ms per token,   102.47 tokens per second)\n",
      "llama_print_timings:        eval time =   78266.93 ms /   713 runs   (  109.77 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =  100520.16 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     1 runs   (    0.64 ms per token,  1567.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17410.50 ms /  1744 tokens (    9.98 ms per token,   100.17 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   17454.16 ms /  1745 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     192.69 ms /   368 runs   (    0.52 ms per token,  1909.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3007.49 ms /   295 tokens (   10.19 ms per token,    98.09 tokens per second)\n",
      "llama_print_timings:        eval time =   35555.87 ms /   367 runs   (   96.88 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =   43306.37 ms /   662 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     454.57 ms /   903 runs   (    0.50 ms per token,  1986.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     364.61 ms /    21 tokens (   17.36 ms per token,    57.60 tokens per second)\n",
      "llama_print_timings:        eval time =   85984.54 ms /   902 runs   (   95.33 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =   96864.36 ms /   923 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     178.73 ms /   541 runs   (    0.33 ms per token,  3026.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6466.50 ms /   652 tokens (    9.92 ms per token,   100.83 tokens per second)\n",
      "llama_print_timings:        eval time =   53369.77 ms /   540 runs   (   98.83 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =   65084.31 ms /  1192 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     139.21 ms /   425 runs   (    0.33 ms per token,  3053.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3322.97 ms /   346 tokens (    9.60 ms per token,   104.12 tokens per second)\n",
      "llama_print_timings:        eval time =   40319.76 ms /   424 runs   (   95.09 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =   47493.56 ms /   770 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     323.61 ms /   984 runs   (    0.33 ms per token,  3040.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3963.55 ms /   411 tokens (    9.64 ms per token,   103.69 tokens per second)\n",
      "llama_print_timings:        eval time =   97536.05 ms /   983 runs   (   99.22 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =  111566.30 ms /  1394 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     127.76 ms /   397 runs   (    0.32 ms per token,  3107.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4261.07 ms /   446 tokens (    9.55 ms per token,   104.67 tokens per second)\n",
      "llama_print_timings:        eval time =   38040.76 ms /   396 runs   (   96.06 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =   45853.49 ms /   842 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     187.04 ms /   559 runs   (    0.33 ms per token,  2988.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.30 ms /    24 tokens (   13.89 ms per token,    72.01 tokens per second)\n",
      "llama_print_timings:        eval time =   50981.06 ms /   558 runs   (   91.36 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =   56577.22 ms /   582 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      65.10 ms /   192 runs   (    0.34 ms per token,  2949.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3331.96 ms /   327 tokens (   10.19 ms per token,    98.14 tokens per second)\n",
      "llama_print_timings:        eval time =   17649.09 ms /   191 runs   (   92.40 ms per token,    10.82 tokens per second)\n",
      "llama_print_timings:       total time =   22668.23 ms /   518 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     324.11 ms /  1000 runs   (    0.32 ms per token,  3085.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3016.60 ms /   294 tokens (   10.26 ms per token,    97.46 tokens per second)\n",
      "llama_print_timings:        eval time =   97793.45 ms /   999 runs   (   97.89 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =  110814.31 ms /  1293 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     181.35 ms /   543 runs   (    0.33 ms per token,  2994.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2091.09 ms /   198 tokens (   10.56 ms per token,    94.69 tokens per second)\n",
      "llama_print_timings:        eval time =   51003.95 ms /   542 runs   (   94.10 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =   58310.85 ms /   740 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     6 runs   (    0.36 ms per token,  2768.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11743.81 ms /  1211 tokens (    9.70 ms per token,   103.12 tokens per second)\n",
      "llama_print_timings:        eval time =     514.50 ms /     5 runs   (  102.90 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =   12328.03 ms /  1216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.32 ms per token,  3100.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14040.64 ms /  1433 tokens (    9.80 ms per token,   102.06 tokens per second)\n",
      "llama_print_timings:        eval time =     106.26 ms /     1 runs   (  106.26 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =   14183.07 ms /  1434 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /     6 runs   (    0.34 ms per token,  2951.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20951.65 ms /  1954 tokens (   10.72 ms per token,    93.26 tokens per second)\n",
      "llama_print_timings:        eval time =     571.09 ms /     5 runs   (  114.22 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =   21613.39 ms /  1959 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     318.60 ms /  1000 runs   (    0.32 ms per token,  3138.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8437.34 ms /   862 tokens (    9.79 ms per token,   102.16 tokens per second)\n",
      "llama_print_timings:        eval time =  103501.11 ms /   999 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =  124000.72 ms /  1861 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     107.80 ms /   325 runs   (    0.33 ms per token,  3014.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8196.90 ms /   861 tokens (    9.52 ms per token,   105.04 tokens per second)\n",
      "llama_print_timings:        eval time =   32069.95 ms /   324 runs   (   98.98 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =   43798.27 ms /  1185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     1 runs   (    0.36 ms per token,  2793.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15151.84 ms /  1543 tokens (    9.82 ms per token,   101.84 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   15185.84 ms /  1544 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     154.99 ms /   468 runs   (    0.33 ms per token,  3019.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9816.58 ms /   999 tokens (    9.83 ms per token,   101.77 tokens per second)\n",
      "llama_print_timings:        eval time =   47415.31 ms /   467 runs   (  101.53 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =   62452.00 ms /  1466 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     124.14 ms /   308 runs   (    0.40 ms per token,  2480.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.05 ms /    18 tokens (   18.11 ms per token,    55.21 tokens per second)\n",
      "llama_print_timings:        eval time =   27141.85 ms /   307 runs   (   88.41 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =   30664.35 ms /   325 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     135.54 ms /   406 runs   (    0.33 ms per token,  2995.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2955.84 ms /   297 tokens (    9.95 ms per token,   100.48 tokens per second)\n",
      "llama_print_timings:        eval time =   37223.93 ms /   405 runs   (   91.91 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =   44524.61 ms /   702 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     127.04 ms /   370 runs   (    0.34 ms per token,  2912.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7569.49 ms /   771 tokens (    9.82 ms per token,   101.86 tokens per second)\n",
      "llama_print_timings:        eval time =   36200.69 ms /   369 runs   (   98.10 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =   47761.96 ms /  1140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     131.15 ms /   372 runs   (    0.35 ms per token,  2836.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7570.49 ms /   788 tokens (    9.61 ms per token,   104.09 tokens per second)\n",
      "llama_print_timings:        eval time =   36487.65 ms /   371 runs   (   98.35 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =   48035.14 ms /  1159 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     3 runs   (    0.35 ms per token,  2832.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16404.56 ms /  1689 tokens (    9.71 ms per token,   102.96 tokens per second)\n",
      "llama_print_timings:        eval time =     214.12 ms /     2 runs   (  107.06 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =   16673.87 ms /  1691 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     2 runs   (    0.36 ms per token,  2773.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15747.98 ms /  1614 tokens (    9.76 ms per token,   102.49 tokens per second)\n",
      "llama_print_timings:        eval time =     106.20 ms /     1 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =   15899.96 ms /  1615 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     4 runs   (    0.38 ms per token,  2614.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9823.67 ms /   998 tokens (    9.84 ms per token,   101.59 tokens per second)\n",
      "llama_print_timings:        eval time =     296.63 ms /     3 runs   (   98.88 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =   10167.13 ms /  1001 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      31.53 ms /    85 runs   (    0.37 ms per token,  2696.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.53 ms /    17 tokens (   18.97 ms per token,    52.71 tokens per second)\n",
      "llama_print_timings:        eval time =    7340.14 ms /    84 runs   (   87.38 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    8467.89 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     246.10 ms /   599 runs   (    0.41 ms per token,  2433.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.67 ms /    16 tokens (   19.98 ms per token,    50.05 tokens per second)\n",
      "llama_print_timings:        eval time =   53717.90 ms /   598 runs   (   89.83 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =   60541.71 ms /   614 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     331.43 ms /  1000 runs   (    0.33 ms per token,  3017.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8480.34 ms /   877 tokens (    9.67 ms per token,   103.42 tokens per second)\n",
      "llama_print_timings:        eval time =  102457.65 ms /   999 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =  122632.58 ms /  1876 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     329.33 ms /  1000 runs   (    0.33 ms per token,  3036.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7547.44 ms /   772 tokens (    9.78 ms per token,   102.29 tokens per second)\n",
      "llama_print_timings:        eval time =  101810.13 ms /   999 runs   (  101.91 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =  121204.81 ms /  1771 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     184.64 ms /   549 runs   (    0.34 ms per token,  2973.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5442.98 ms /   556 tokens (    9.79 ms per token,   102.15 tokens per second)\n",
      "llama_print_timings:        eval time =   52906.95 ms /   548 runs   (   96.55 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =   64498.26 ms /  1104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      83.41 ms /   237 runs   (    0.35 ms per token,  2841.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.74 ms /    17 tokens (   19.04 ms per token,    52.51 tokens per second)\n",
      "llama_print_timings:        eval time =   20734.72 ms /   236 runs   (   87.86 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =   23489.71 ms /   253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      72.79 ms /   220 runs   (    0.33 ms per token,  3022.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17933.44 ms /  1827 tokens (    9.82 ms per token,   101.88 tokens per second)\n",
      "llama_print_timings:        eval time =   23917.05 ms /   219 runs   (  109.21 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =   44269.72 ms /  2046 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     4 runs   (    0.34 ms per token,  2973.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18639.32 ms /  1895 tokens (    9.84 ms per token,   101.67 tokens per second)\n",
      "llama_print_timings:        eval time =     328.66 ms /     3 runs   (  109.55 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =   19034.39 ms /  1898 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      45.96 ms /   137 runs   (    0.34 ms per token,  2980.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5457.48 ms /   574 tokens (    9.51 ms per token,   105.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12823.16 ms /   136 runs   (   94.29 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =   19663.95 ms /   710 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      27.08 ms /    81 runs   (    0.33 ms per token,  2991.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3577.45 ms /   374 tokens (    9.57 ms per token,   104.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7324.21 ms /    80 runs   (   91.55 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =   11713.79 ms /   454 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     123.68 ms /   361 runs   (    0.34 ms per token,  2918.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2664.76 ms /   273 tokens (    9.76 ms per token,   102.45 tokens per second)\n",
      "llama_print_timings:        eval time =   33131.55 ms /   360 runs   (   92.03 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =   39651.79 ms /   633 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     3 runs   (    0.35 ms per token,  2892.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18945.98 ms /  1948 tokens (    9.73 ms per token,   102.82 tokens per second)\n",
      "llama_print_timings:        eval time =     220.05 ms /     2 runs   (  110.03 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =   19225.95 ms /  1950 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     127.25 ms /   373 runs   (    0.34 ms per token,  2931.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3576.79 ms /   374 tokens (    9.56 ms per token,   104.56 tokens per second)\n",
      "llama_print_timings:        eval time =   34703.24 ms /   372 runs   (   93.29 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =   42235.82 ms /   746 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     314.10 ms /   942 runs   (    0.33 ms per token,  2999.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2958.74 ms /   313 tokens (    9.45 ms per token,   105.79 tokens per second)\n",
      "llama_print_timings:        eval time =   90395.43 ms /   941 runs   (   96.06 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =  104302.35 ms /  1254 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      94.99 ms /   282 runs   (    0.34 ms per token,  2968.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2375.30 ms /   247 tokens (    9.62 ms per token,   103.99 tokens per second)\n",
      "llama_print_timings:        eval time =   25635.84 ms /   281 runs   (   91.23 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =   30977.48 ms /   528 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     323.23 ms /  1000 runs   (    0.32 ms per token,  3093.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7251.48 ms /   752 tokens (    9.64 ms per token,   103.70 tokens per second)\n",
      "llama_print_timings:        eval time =  101577.09 ms /   999 runs   (  101.68 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =  120808.63 ms /  1751 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     121.18 ms /   370 runs   (    0.33 ms per token,  3053.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4904.99 ms /   496 tokens (    9.89 ms per token,   101.12 tokens per second)\n",
      "llama_print_timings:        eval time =   34958.48 ms /   369 runs   (   94.74 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =   43916.85 ms /   865 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     136.73 ms /   423 runs   (    0.32 ms per token,  3093.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12553.17 ms /  1312 tokens (    9.57 ms per token,   104.52 tokens per second)\n",
      "llama_print_timings:        eval time =   44289.95 ms /   422 runs   (  104.95 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   61624.31 ms /  1734 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     117.70 ms /   339 runs   (    0.35 ms per token,  2880.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4205.24 ms /   426 tokens (    9.87 ms per token,   101.30 tokens per second)\n",
      "llama_print_timings:        eval time =   31658.57 ms /   338 runs   (   93.66 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   39496.91 ms /   764 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     318.15 ms /  1000 runs   (    0.32 ms per token,  3143.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7855.13 ms /   810 tokens (    9.70 ms per token,   103.12 tokens per second)\n",
      "llama_print_timings:        eval time =  102255.65 ms /   999 runs   (  102.36 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =  122067.85 ms /  1809 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      92.37 ms /   285 runs   (    0.32 ms per token,  3085.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10971.14 ms /  1129 tokens (    9.72 ms per token,   102.91 tokens per second)\n",
      "llama_print_timings:        eval time =   28962.82 ms /   284 runs   (  101.98 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =   43013.58 ms /  1413 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      20.03 ms /    75 runs   (    0.27 ms per token,  3743.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7332.78 ms /   766 tokens (    9.57 ms per token,   104.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7679.75 ms /    74 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =   15624.41 ms /   840 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      87.84 ms /   181 runs   (    0.49 ms per token,  2060.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4406.19 ms /   422 tokens (   10.44 ms per token,    95.77 tokens per second)\n",
      "llama_print_timings:        eval time =   17495.29 ms /   180 runs   (   97.20 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =   24062.48 ms /   602 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     168.21 ms /   298 runs   (    0.56 ms per token,  1771.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5168.57 ms /   517 tokens (   10.00 ms per token,   100.03 tokens per second)\n",
      "llama_print_timings:        eval time =   28598.41 ms /   297 runs   (   96.29 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =   38139.88 ms /   814 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     295.26 ms /   561 runs   (    0.53 ms per token,  1900.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2465.03 ms /   250 tokens (    9.86 ms per token,   101.42 tokens per second)\n",
      "llama_print_timings:        eval time =   53296.12 ms /   560 runs   (   95.17 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =   63866.52 ms /   810 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      91.68 ms /   153 runs   (    0.60 ms per token,  1668.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2680.58 ms /   283 tokens (    9.47 ms per token,   105.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14018.81 ms /   152 runs   (   92.23 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =   18852.02 ms /   435 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     405.56 ms /   698 runs   (    0.58 ms per token,  1721.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3591.77 ms /   355 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =   66696.29 ms /   697 runs   (   95.69 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =   81660.06 ms /  1052 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     383.17 ms /   565 runs   (    0.68 ms per token,  1474.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.70 ms /    16 tokens (   19.98 ms per token,    50.05 tokens per second)\n",
      "llama_print_timings:        eval time =   50896.87 ms /   564 runs   (   90.24 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =   60050.05 ms /   580 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     504.34 ms /   874 runs   (    0.58 ms per token,  1732.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2361.71 ms /   244 tokens (    9.68 ms per token,   103.32 tokens per second)\n",
      "llama_print_timings:        eval time =   82500.56 ms /   873 runs   (   94.50 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =   98853.26 ms /  1117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     235.57 ms /   396 runs   (    0.59 ms per token,  1681.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5173.71 ms /   523 tokens (    9.89 ms per token,   101.09 tokens per second)\n",
      "llama_print_timings:        eval time =   37900.22 ms /   395 runs   (   95.95 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =   49062.07 ms /   918 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      17.66 ms /    30 runs   (    0.59 ms per token,  1698.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2384.78 ms /   252 tokens (    9.46 ms per token,   105.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2623.49 ms /    29 runs   (   90.47 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    5416.61 ms /   281 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     570.06 ms /   973 runs   (    0.59 ms per token,  1706.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3887.61 ms /   412 tokens (    9.44 ms per token,   105.98 tokens per second)\n",
      "llama_print_timings:        eval time =   95103.24 ms /   972 runs   (   97.84 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =  115108.87 ms /  1384 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     3 runs   (    0.56 ms per token,  1775.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4211.82 ms /   426 tokens (    9.89 ms per token,   101.14 tokens per second)\n",
      "llama_print_timings:        eval time =     183.84 ms /     2 runs   (   91.92 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =    4433.57 ms /   428 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     2 runs   (    0.57 ms per token,  1759.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18051.38 ms /  1828 tokens (    9.87 ms per token,   101.27 tokens per second)\n",
      "llama_print_timings:        eval time =     109.54 ms /     1 runs   (  109.54 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =   18229.21 ms /  1829 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      89.13 ms /   149 runs   (    0.60 ms per token,  1671.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2065.61 ms /   207 tokens (    9.98 ms per token,   100.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13415.21 ms /   148 runs   (   90.64 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =   17568.32 ms /   355 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      84.77 ms /   144 runs   (    0.59 ms per token,  1698.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9470.27 ms /   990 tokens (    9.57 ms per token,   104.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14311.40 ms /   143 runs   (  100.08 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =   25880.65 ms /  1133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     569.56 ms /  1000 runs   (    0.57 ms per token,  1755.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4207.23 ms /   439 tokens (    9.58 ms per token,   104.34 tokens per second)\n",
      "llama_print_timings:        eval time =  100369.12 ms /   999 runs   (  100.47 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =  121342.30 ms /  1438 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     220.58 ms /   389 runs   (    0.57 ms per token,  1763.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2991.25 ms /   289 tokens (   10.35 ms per token,    96.62 tokens per second)\n",
      "llama_print_timings:        eval time =   36246.89 ms /   388 runs   (   93.42 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =   45144.96 ms /   677 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     355.06 ms /   499 runs   (    0.71 ms per token,  1405.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.56 ms /    17 tokens (   18.97 ms per token,    52.70 tokens per second)\n",
      "llama_print_timings:        eval time =   44764.31 ms /   498 runs   (   89.89 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =   52805.32 ms /   515 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     268.81 ms /   465 runs   (    0.58 ms per token,  1729.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3904.24 ms /   393 tokens (    9.93 ms per token,   100.66 tokens per second)\n",
      "llama_print_timings:        eval time =   43601.98 ms /   464 runs   (   93.97 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =   54647.31 ms /   857 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     101.84 ms /   176 runs   (    0.58 ms per token,  1728.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3281.21 ms /   326 tokens (   10.07 ms per token,    99.35 tokens per second)\n",
      "llama_print_timings:        eval time =   16134.68 ms /   175 runs   (   92.20 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =   21910.19 ms /   501 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      81.35 ms /   139 runs   (    0.59 ms per token,  1708.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4216.53 ms /   421 tokens (   10.02 ms per token,    99.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12836.39 ms /   138 runs   (   93.02 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =   19038.82 ms /   559 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     350.88 ms /   589 runs   (    0.60 ms per token,  1678.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.75 ms /    15 tokens (   21.32 ms per token,    46.91 tokens per second)\n",
      "llama_print_timings:        eval time =   53214.74 ms /   588 runs   (   90.50 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =   62606.85 ms /   603 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     3 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11620.20 ms /  1186 tokens (    9.80 ms per token,   102.06 tokens per second)\n",
      "llama_print_timings:        eval time =     201.47 ms /     2 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =   11887.39 ms /  1188 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.11 ms /     2 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9127.45 ms /   958 tokens (    9.53 ms per token,   104.96 tokens per second)\n",
      "llama_print_timings:        eval time =      99.30 ms /     1 runs   (   99.30 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    9266.11 ms /   959 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     164.60 ms /   282 runs   (    0.58 ms per token,  1713.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2967.03 ms /   320 tokens (    9.27 ms per token,   107.85 tokens per second)\n",
      "llama_print_timings:        eval time =   26137.76 ms /   281 runs   (   93.02 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =   33281.39 ms /   601 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     260.13 ms /   447 runs   (    0.58 ms per token,  1718.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2652.96 ms /   257 tokens (   10.32 ms per token,    96.87 tokens per second)\n",
      "llama_print_timings:        eval time =   41580.96 ms /   446 runs   (   93.23 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =   51082.88 ms /   703 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     6 runs   (    0.58 ms per token,  1722.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10966.51 ms /  1126 tokens (    9.74 ms per token,   102.68 tokens per second)\n",
      "llama_print_timings:        eval time =     507.03 ms /     5 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =   11583.33 ms /  1131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     3 runs   (    0.60 ms per token,  1680.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9155.61 ms /   951 tokens (    9.63 ms per token,   103.87 tokens per second)\n",
      "llama_print_timings:        eval time =     196.77 ms /     2 runs   (   98.38 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =    9407.25 ms /   953 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     6 runs   (    0.56 ms per token,  1772.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9122.48 ms /   957 tokens (    9.53 ms per token,   104.91 tokens per second)\n",
      "llama_print_timings:        eval time =     491.77 ms /     5 runs   (   98.35 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =    9709.12 ms /   962 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     576.40 ms /  1000 runs   (    0.58 ms per token,  1734.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7560.57 ms /   783 tokens (    9.66 ms per token,   103.56 tokens per second)\n",
      "llama_print_timings:        eval time =  102399.79 ms /   999 runs   (  102.50 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =  126575.25 ms /  1782 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     281.68 ms /   470 runs   (    0.60 ms per token,  1668.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2076.29 ms /   211 tokens (    9.84 ms per token,   101.62 tokens per second)\n",
      "llama_print_timings:        eval time =   43396.31 ms /   469 runs   (   92.53 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =   52623.08 ms /   680 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     536.22 ms /   893 runs   (    0.60 ms per token,  1665.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2070.74 ms /   217 tokens (    9.54 ms per token,   104.79 tokens per second)\n",
      "llama_print_timings:        eval time =   84718.34 ms /   892 runs   (   94.98 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =  101540.79 ms /  1109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     312.54 ms /   509 runs   (    0.61 ms per token,  1628.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.17 ms /    13 tokens (   24.55 ms per token,    40.73 tokens per second)\n",
      "llama_print_timings:        eval time =   45647.87 ms /   508 runs   (   89.86 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =   53687.14 ms /   521 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     506.58 ms /   775 runs   (    0.65 ms per token,  1529.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     313.37 ms /    10 tokens (   31.34 ms per token,    31.91 tokens per second)\n",
      "llama_print_timings:        eval time =   70643.10 ms /   774 runs   (   91.27 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =   83218.04 ms /   784 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     583.93 ms /  1000 runs   (    0.58 ms per token,  1712.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6964.89 ms /   733 tokens (    9.50 ms per token,   105.24 tokens per second)\n",
      "llama_print_timings:        eval time =  101033.20 ms /   999 runs   (  101.13 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =  124378.43 ms /  1732 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     247.61 ms /   346 runs   (    0.72 ms per token,  1397.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     318.41 ms /    16 tokens (   19.90 ms per token,    50.25 tokens per second)\n",
      "llama_print_timings:        eval time =   30708.24 ms /   345 runs   (   89.01 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =   36021.33 ms /   361 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     207.54 ms /   344 runs   (    0.60 ms per token,  1657.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3563.86 ms /   361 tokens (    9.87 ms per token,   101.29 tokens per second)\n",
      "llama_print_timings:        eval time =   31858.35 ms /   343 runs   (   92.88 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =   40392.45 ms /   704 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     483.70 ms /   782 runs   (    0.62 ms per token,  1616.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     318.29 ms /    15 tokens (   21.22 ms per token,    47.13 tokens per second)\n",
      "llama_print_timings:        eval time =   71362.38 ms /   781 runs   (   91.37 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =   84033.81 ms /   796 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16684.88 ms /  1728 tokens (    9.66 ms per token,   103.57 tokens per second)\n",
      "llama_print_timings:        eval time =     106.88 ms /     1 runs   (  106.88 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =   16856.46 ms /  1729 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     235.02 ms /   394 runs   (    0.60 ms per token,  1676.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7559.41 ms /   797 tokens (    9.48 ms per token,   105.43 tokens per second)\n",
      "llama_print_timings:        eval time =   38997.12 ms /   393 runs   (   99.23 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =   52453.15 ms /  1190 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     3 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10963.01 ms /  1127 tokens (    9.73 ms per token,   102.80 tokens per second)\n",
      "llama_print_timings:        eval time =     201.36 ms /     2 runs   (  100.68 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =   11228.02 ms /  1129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     508.47 ms /   880 runs   (    0.58 ms per token,  1730.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10689.21 ms /  1108 tokens (    9.65 ms per token,   103.66 tokens per second)\n",
      "llama_print_timings:        eval time =   93108.44 ms /   879 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =  118490.83 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     136.43 ms /   231 runs   (    0.59 ms per token,  1693.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3593.15 ms /   374 tokens (    9.61 ms per token,   104.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21393.26 ms /   230 runs   (   93.01 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =   28294.81 ms /   604 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     580.96 ms /  1000 runs   (    0.58 ms per token,  1721.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8502.89 ms /   882 tokens (    9.64 ms per token,   103.73 tokens per second)\n",
      "llama_print_timings:        eval time =  103486.19 ms /   999 runs   (  103.59 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =  128718.92 ms /  1881 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     384.08 ms /   659 runs   (    0.58 ms per token,  1715.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2663.47 ms /   281 tokens (    9.48 ms per token,   105.50 tokens per second)\n",
      "llama_print_timings:        eval time =   62105.65 ms /   658 runs   (   94.39 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =   75173.16 ms /   939 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     432.41 ms /   752 runs   (    0.58 ms per token,  1739.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11933.57 ms /  1236 tokens (    9.65 ms per token,   103.57 tokens per second)\n",
      "llama_print_timings:        eval time =   79938.39 ms /   751 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =  104008.72 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     129.36 ms /   224 runs   (    0.58 ms per token,  1731.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2060.64 ms /   197 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =   20248.33 ms /   223 runs   (   90.80 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =   25495.70 ms /   420 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      94.56 ms /   165 runs   (    0.57 ms per token,  1745.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2367.98 ms /   241 tokens (    9.83 ms per token,   101.77 tokens per second)\n",
      "llama_print_timings:        eval time =   14931.37 ms /   164 runs   (   91.04 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =   19584.39 ms /   405 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     184.42 ms /   314 runs   (    0.59 ms per token,  1702.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2070.01 ms /   218 tokens (    9.50 ms per token,   105.31 tokens per second)\n",
      "llama_print_timings:        eval time =   28663.66 ms /   313 runs   (   91.58 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =   35317.06 ms /   531 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     186.83 ms /   320 runs   (    0.58 ms per token,  1712.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2372.10 ms /   245 tokens (    9.68 ms per token,   103.28 tokens per second)\n",
      "llama_print_timings:        eval time =   29369.25 ms /   319 runs   (   92.07 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =   36400.66 ms /   564 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     247.98 ms /   418 runs   (    0.59 ms per token,  1685.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2670.10 ms /   272 tokens (    9.82 ms per token,   101.87 tokens per second)\n",
      "llama_print_timings:        eval time =   38715.57 ms /   417 runs   (   92.84 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =   47650.59 ms /   689 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      91.08 ms /   172 runs   (    0.53 ms per token,  1888.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8504.09 ms /   878 tokens (    9.69 ms per token,   103.24 tokens per second)\n",
      "llama_print_timings:        eval time =   16972.39 ms /   171 runs   (   99.25 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =   27734.21 ms /  1049 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     184.23 ms /   323 runs   (    0.57 ms per token,  1753.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2376.23 ms /   247 tokens (    9.62 ms per token,   103.95 tokens per second)\n",
      "llama_print_timings:        eval time =   29701.57 ms /   322 runs   (   92.24 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =   36635.83 ms /   569 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     309.97 ms /   535 runs   (    0.58 ms per token,  1725.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8181.86 ms /   857 tokens (    9.55 ms per token,   104.74 tokens per second)\n",
      "llama_print_timings:        eval time =   53751.84 ms /   534 runs   (  100.66 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =   70368.27 ms /  1391 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     118.80 ms /   232 runs   (    0.51 ms per token,  1952.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17044.93 ms /  1755 tokens (    9.71 ms per token,   102.96 tokens per second)\n",
      "llama_print_timings:        eval time =   26344.54 ms /   231 runs   (  114.05 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =   46550.02 ms /  1986 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     386.73 ms /   669 runs   (    0.58 ms per token,  1729.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12412.46 ms /  1273 tokens (    9.75 ms per token,   102.56 tokens per second)\n",
      "llama_print_timings:        eval time =   71171.82 ms /   668 runs   (  106.54 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   94621.76 ms /  1941 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17129.56 ms /  1754 tokens (    9.77 ms per token,   102.40 tokens per second)\n",
      "llama_print_timings:        eval time =     651.00 ms /     6 runs   (  108.50 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =   17918.87 ms /  1760 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     587.97 ms /  1000 runs   (    0.59 ms per token,  1700.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2367.18 ms /   231 tokens (   10.25 ms per token,    97.58 tokens per second)\n",
      "llama_print_timings:        eval time =  166228.87 ms /   999 runs   (  166.40 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =  185582.37 ms /  1230 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     358.12 ms /   602 runs   (    0.59 ms per token,  1680.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4510.64 ms /   254 tokens (   17.76 ms per token,    56.31 tokens per second)\n",
      "llama_print_timings:        eval time =  106407.51 ms /   601 runs   (  177.05 ms per token,     5.65 tokens per second)\n",
      "llama_print_timings:       total time =  120237.17 ms /   855 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      99.65 ms /   163 runs   (    0.61 ms per token,  1635.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10140.67 ms /   490 tokens (   20.70 ms per token,    48.32 tokens per second)\n",
      "llama_print_timings:        eval time =   29248.64 ms /   162 runs   (  180.55 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   41660.85 ms /   652 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     224.49 ms /   376 runs   (    0.60 ms per token,  1674.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     554.93 ms /    10 tokens (   55.49 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   63953.95 ms /   375 runs   (  170.54 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:       total time =   70008.11 ms /   385 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     1 runs   (    0.61 ms per token,  1631.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35584.49 ms /  1745 tokens (   20.39 ms per token,    49.04 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   35633.57 ms /  1746 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     157.73 ms /   254 runs   (    0.62 ms per token,  1610.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     538.32 ms /    15 tokens (   35.89 ms per token,    27.86 tokens per second)\n",
      "llama_print_timings:        eval time =   42908.76 ms /   253 runs   (  169.60 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:       total time =   46971.37 ms /   268 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     707.61 ms /  1000 runs   (    0.71 ms per token,  1413.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     529.32 ms /    13 tokens (   40.72 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:        eval time =  173944.65 ms /   999 runs   (  174.12 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =  191179.11 ms /  1012 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     279.58 ms /   471 runs   (    0.59 ms per token,  1684.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6244.26 ms /   338 tokens (   18.47 ms per token,    54.13 tokens per second)\n",
      "llama_print_timings:        eval time =   82887.38 ms /   470 runs   (  176.36 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:       total time =   96171.35 ms /   808 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     426.70 ms /   724 runs   (    0.59 ms per token,  1696.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5015.90 ms /   275 tokens (   18.24 ms per token,    54.83 tokens per second)\n",
      "llama_print_timings:        eval time =  128787.41 ms /   723 runs   (  178.13 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:       total time =  145407.60 ms /   998 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     592.08 ms /  1000 runs   (    0.59 ms per token,  1688.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4956.88 ms /   259 tokens (   19.14 ms per token,    52.25 tokens per second)\n",
      "llama_print_timings:        eval time =  179500.31 ms /   999 runs   (  179.68 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =  201272.68 ms /  1258 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     275.76 ms /   467 runs   (    0.59 ms per token,  1693.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6879.97 ms /   365 tokens (   18.85 ms per token,    53.05 tokens per second)\n",
      "llama_print_timings:        eval time =   82717.80 ms /   466 runs   (  177.51 ms per token,     5.63 tokens per second)\n",
      "llama_print_timings:       total time =   96714.98 ms /   831 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     265.47 ms /   447 runs   (    0.59 ms per token,  1683.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4442.51 ms /   250 tokens (   17.77 ms per token,    56.27 tokens per second)\n",
      "llama_print_timings:        eval time =   78164.87 ms /   446 runs   (  175.26 ms per token,     5.71 tokens per second)\n",
      "llama_print_timings:       total time =   89395.68 ms /   696 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     157.09 ms /   266 runs   (    0.59 ms per token,  1693.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5625.79 ms /   313 tokens (   17.97 ms per token,    55.64 tokens per second)\n",
      "llama_print_timings:        eval time =   46602.05 ms /   265 runs   (  175.86 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   56064.37 ms /   578 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     5 runs   (    0.59 ms per token,  1682.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19044.75 ms /   946 tokens (   20.13 ms per token,    49.67 tokens per second)\n",
      "llama_print_timings:        eval time =     724.19 ms /     4 runs   (  181.05 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:       total time =   19852.23 ms /   950 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     509.45 ms /   889 runs   (    0.57 ms per token,  1745.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4390.55 ms /   227 tokens (   19.34 ms per token,    51.70 tokens per second)\n",
      "llama_print_timings:        eval time =  158090.43 ms /   888 runs   (  178.03 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:       total time =  177310.15 ms /  1115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     105.31 ms /   180 runs   (    0.59 ms per token,  1709.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3868.95 ms /   221 tokens (   17.51 ms per token,    57.12 tokens per second)\n",
      "llama_print_timings:        eval time =   30930.63 ms /   179 runs   (  172.80 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:       total time =   37357.56 ms /   400 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     579.51 ms /  1000 runs   (    0.58 ms per token,  1725.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6189.80 ms /   326 tokens (   18.99 ms per token,    52.67 tokens per second)\n",
      "llama_print_timings:        eval time =  180685.11 ms /   999 runs   (  180.87 ms per token,     5.53 tokens per second)\n",
      "llama_print_timings:       total time =  203612.21 ms /  1325 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     317.57 ms /   538 runs   (    0.59 ms per token,  1694.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15361.73 ms /   787 tokens (   19.52 ms per token,    51.23 tokens per second)\n",
      "llama_print_timings:        eval time =   99723.74 ms /   537 runs   (  185.71 ms per token,     5.38 tokens per second)\n",
      "llama_print_timings:       total time =  123661.78 ms /  1324 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     1 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29470.84 ms /  1450 tokens (   20.32 ms per token,    49.20 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   29509.10 ms /  1451 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     207.40 ms /   356 runs   (    0.58 ms per token,  1716.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3241.44 ms /   180 tokens (   18.01 ms per token,    55.53 tokens per second)\n",
      "llama_print_timings:        eval time =   61645.50 ms /   355 runs   (  173.65 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:       total time =   70194.15 ms /   535 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     196.68 ms /   338 runs   (    0.58 ms per token,  1718.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4962.71 ms /   267 tokens (   18.59 ms per token,    53.80 tokens per second)\n",
      "llama_print_timings:        eval time =   58912.56 ms /   337 runs   (  174.81 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   68936.79 ms /   604 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /     9 runs   (    0.58 ms per token,  1717.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16608.28 ms /   845 tokens (   19.65 ms per token,    50.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1449.76 ms /     8 runs   (  181.22 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:       total time =   18193.08 ms /   853 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     565.28 ms /  1000 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16685.46 ms /   856 tokens (   19.49 ms per token,    51.30 tokens per second)\n",
      "llama_print_timings:        eval time =  190378.95 ms /   999 runs   (  190.57 ms per token,     5.25 tokens per second)\n",
      "llama_print_timings:       total time =  224262.81 ms /  1855 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     310.82 ms /   526 runs   (    0.59 ms per token,  1692.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3806.89 ms /   205 tokens (   18.57 ms per token,    53.85 tokens per second)\n",
      "llama_print_timings:        eval time =   91694.05 ms /   525 runs   (  174.66 ms per token,     5.73 tokens per second)\n",
      "llama_print_timings:       total time =  103758.24 ms /   730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     571.75 ms /  1000 runs   (    0.57 ms per token,  1749.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16590.44 ms /   840 tokens (   19.75 ms per token,    50.63 tokens per second)\n",
      "llama_print_timings:        eval time =  190327.25 ms /   999 runs   (  190.52 ms per token,     5.25 tokens per second)\n",
      "llama_print_timings:       total time =  223991.41 ms /  1839 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     182.57 ms /   307 runs   (    0.59 ms per token,  1681.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4980.83 ms /   272 tokens (   18.31 ms per token,    54.61 tokens per second)\n",
      "llama_print_timings:        eval time =   53344.95 ms /   306 runs   (  174.33 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   62930.75 ms /   578 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     151.69 ms /   264 runs   (    0.57 ms per token,  1740.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20573.21 ms /  1007 tokens (   20.43 ms per token,    48.95 tokens per second)\n",
      "llama_print_timings:        eval time =   49393.56 ms /   263 runs   (  187.81 ms per token,     5.32 tokens per second)\n",
      "llama_print_timings:       total time =   73989.47 ms /  1270 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     567.89 ms /  1000 runs   (    0.57 ms per token,  1760.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16522.19 ms /   847 tokens (   19.51 ms per token,    51.26 tokens per second)\n",
      "llama_print_timings:        eval time =  190814.61 ms /   999 runs   (  191.01 ms per token,     5.24 tokens per second)\n",
      "llama_print_timings:       total time =  223847.58 ms /  1846 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     584.35 ms /   995 runs   (    0.59 ms per token,  1702.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3830.64 ms /   207 tokens (   18.51 ms per token,    54.04 tokens per second)\n",
      "llama_print_timings:        eval time =  177850.82 ms /   994 runs   (  178.92 ms per token,     5.59 tokens per second)\n",
      "llama_print_timings:       total time =  198232.85 ms /  1201 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     4 runs   (    0.57 ms per token,  1747.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3853.93 ms /   202 tokens (   19.08 ms per token,    52.41 tokens per second)\n",
      "llama_print_timings:        eval time =     496.07 ms /     3 runs   (  165.36 ms per token,     6.05 tokens per second)\n",
      "llama_print_timings:       total time =    4401.00 ms /   205 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     578.01 ms /  1000 runs   (    0.58 ms per token,  1730.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19022.02 ms /   951 tokens (   20.00 ms per token,    49.99 tokens per second)\n",
      "llama_print_timings:        eval time =  192630.88 ms /   999 runs   (  192.82 ms per token,     5.19 tokens per second)\n",
      "llama_print_timings:       total time =  228313.75 ms /  1950 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     503.30 ms /  1000 runs   (    0.50 ms per token,  1986.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16037.23 ms /   820 tokens (   19.56 ms per token,    51.13 tokens per second)\n",
      "llama_print_timings:        eval time =  203346.27 ms /   999 runs   (  203.55 ms per token,     4.91 tokens per second)\n",
      "llama_print_timings:       total time =  233949.68 ms /  1819 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     333.04 ms /  1000 runs   (    0.33 ms per token,  3002.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6049.04 ms /   298 tokens (   20.30 ms per token,    49.26 tokens per second)\n",
      "llama_print_timings:        eval time =  186906.54 ms /   999 runs   (  187.09 ms per token,     5.34 tokens per second)\n",
      "llama_print_timings:       total time =  204625.16 ms /  1297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     188.45 ms /   548 runs   (    0.34 ms per token,  2907.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3869.14 ms /   210 tokens (   18.42 ms per token,    54.28 tokens per second)\n",
      "llama_print_timings:        eval time =   98201.04 ms /   547 runs   (  179.53 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:       total time =  108163.29 ms /   757 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /    10 runs   (    0.33 ms per token,  3030.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3808.38 ms /   205 tokens (   18.58 ms per token,    53.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1547.55 ms /     9 runs   (  171.95 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =    5453.60 ms /   214 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     162.71 ms /   477 runs   (    0.34 ms per token,  2931.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6122.70 ms /   322 tokens (   19.01 ms per token,    52.59 tokens per second)\n",
      "llama_print_timings:        eval time =   86452.29 ms /   476 runs   (  181.62 ms per token,     5.51 tokens per second)\n",
      "llama_print_timings:       total time =   97756.09 ms /   798 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     168.19 ms /   498 runs   (    0.34 ms per token,  2960.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5563.42 ms /   295 tokens (   18.86 ms per token,    53.02 tokens per second)\n",
      "llama_print_timings:        eval time =   89633.03 ms /   497 runs   (  180.35 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =  100678.72 ms /   792 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     106.38 ms /   306 runs   (    0.35 ms per token,  2876.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4343.70 ms /   233 tokens (   18.64 ms per token,    53.64 tokens per second)\n",
      "llama_print_timings:        eval time =   54810.07 ms /   305 runs   (  179.71 ms per token,     5.56 tokens per second)\n",
      "llama_print_timings:       total time =   62350.88 ms /   538 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     175.45 ms /   441 runs   (    0.40 ms per token,  2513.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     570.43 ms /    24 tokens (   23.77 ms per token,    42.07 tokens per second)\n",
      "llama_print_timings:        eval time =   76615.39 ms /   440 runs   (  174.13 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:       total time =   81992.75 ms /   464 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     2 runs   (    0.31 ms per token,  3179.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37797.19 ms /  1863 tokens (   20.29 ms per token,    49.29 tokens per second)\n",
      "llama_print_timings:        eval time =     185.38 ms /     1 runs   (  185.38 ms per token,     5.39 tokens per second)\n",
      "llama_print_timings:       total time =   38027.60 ms /  1864 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     4 runs   (    0.35 ms per token,  2855.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16586.04 ms /   843 tokens (   19.68 ms per token,    50.83 tokens per second)\n",
      "llama_print_timings:        eval time =     541.35 ms /     3 runs   (  180.45 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:       total time =   17175.91 ms /   846 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /     4 runs   (    0.33 ms per token,  3003.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34963.22 ms /  1697 tokens (   20.60 ms per token,    48.54 tokens per second)\n",
      "llama_print_timings:        eval time =     581.77 ms /     3 runs   (  193.92 ms per token,     5.16 tokens per second)\n",
      "llama_print_timings:       total time =   35612.08 ms /  1700 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     2 runs   (    0.32 ms per token,  3154.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16497.06 ms /   836 tokens (   19.73 ms per token,    50.68 tokens per second)\n",
      "llama_print_timings:        eval time =     167.02 ms /     1 runs   (  167.02 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:       total time =   16691.79 ms /   837 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     128.86 ms /   376 runs   (    0.34 ms per token,  2917.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4976.61 ms /   273 tokens (   18.23 ms per token,    54.86 tokens per second)\n",
      "llama_print_timings:        eval time =   55894.60 ms /   375 runs   (  149.05 ms per token,     6.71 tokens per second)\n",
      "llama_print_timings:       total time =   64856.78 ms /   648 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     241.81 ms /   718 runs   (    0.34 ms per token,  2969.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2380.89 ms /   242 tokens (    9.84 ms per token,   101.64 tokens per second)\n",
      "llama_print_timings:        eval time =   67204.92 ms /   717 runs   (   93.73 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =   77539.31 ms /   959 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     135.47 ms /   406 runs   (    0.33 ms per token,  2997.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8497.95 ms /   876 tokens (    9.70 ms per token,   103.08 tokens per second)\n",
      "llama_print_timings:        eval time =   40897.11 ms /   405 runs   (  100.98 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =   53791.65 ms /  1281 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     116.12 ms /   337 runs   (    0.34 ms per token,  2902.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8237.17 ms /   862 tokens (    9.56 ms per token,   104.65 tokens per second)\n",
      "llama_print_timings:        eval time =   33312.85 ms /   336 runs   (   99.15 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =   45182.78 ms /  1198 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     102.98 ms /   308 runs   (    0.33 ms per token,  2990.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2379.47 ms /   245 tokens (    9.71 ms per token,   102.96 tokens per second)\n",
      "llama_print_timings:        eval time =   28060.71 ms /   307 runs   (   91.40 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =   33760.77 ms /   552 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     324.93 ms /  1000 runs   (    0.32 ms per token,  3077.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8186.25 ms /   844 tokens (    9.70 ms per token,   103.10 tokens per second)\n",
      "llama_print_timings:        eval time =  102660.32 ms /   999 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =  122846.75 ms /  1843 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     200.58 ms /   600 runs   (    0.33 ms per token,  2991.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2652.63 ms /   258 tokens (   10.28 ms per token,    97.26 tokens per second)\n",
      "llama_print_timings:        eval time =   55885.48 ms /   599 runs   (   93.30 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =   65336.66 ms /   857 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     324.02 ms /  1000 runs   (    0.32 ms per token,  3086.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8487.92 ms /   868 tokens (    9.78 ms per token,   102.26 tokens per second)\n",
      "llama_print_timings:        eval time =  103095.97 ms /   999 runs   (  103.20 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =  123369.56 ms /  1867 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     128.47 ms /   376 runs   (    0.34 ms per token,  2926.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2668.94 ms /   268 tokens (    9.96 ms per token,   100.41 tokens per second)\n",
      "llama_print_timings:        eval time =   34519.38 ms /   375 runs   (   92.05 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =   41194.72 ms /   643 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     393.63 ms /  1000 runs   (    0.39 ms per token,  2540.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2435.09 ms /   256 tokens (    9.51 ms per token,   105.13 tokens per second)\n",
      "llama_print_timings:        eval time =   99967.22 ms /   999 runs   (  100.07 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =  114515.69 ms /  1255 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     332.75 ms /  1000 runs   (    0.33 ms per token,  3005.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6843.52 ms /   624 tokens (   10.97 ms per token,    91.18 tokens per second)\n",
      "llama_print_timings:        eval time =  100773.17 ms /   999 runs   (  100.87 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =  118885.84 ms /  1623 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      68.79 ms /   205 runs   (    0.34 ms per token,  2980.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8616.93 ms /   879 tokens (    9.80 ms per token,   102.01 tokens per second)\n",
      "llama_print_timings:        eval time =   20165.12 ms /   204 runs   (   98.85 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =   30778.86 ms /  1083 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     116.50 ms /   352 runs   (    0.33 ms per token,  3021.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3328.00 ms /   328 tokens (   10.15 ms per token,    98.56 tokens per second)\n",
      "llama_print_timings:        eval time =   32664.97 ms /   351 runs   (   93.06 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =   39509.01 ms /   679 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      72.49 ms /   220 runs   (    0.33 ms per token,  3034.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9220.60 ms /   929 tokens (    9.93 ms per token,   100.75 tokens per second)\n",
      "llama_print_timings:        eval time =   21842.62 ms /   219 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =   33226.76 ms /  1148 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     181.81 ms /   536 runs   (    0.34 ms per token,  2948.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2088.08 ms /   222 tokens (    9.41 ms per token,   106.32 tokens per second)\n",
      "llama_print_timings:        eval time =   49770.16 ms /   535 runs   (   93.03 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =   57360.68 ms /   757 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      50.62 ms /   153 runs   (    0.33 ms per token,  3022.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8574.37 ms /   884 tokens (    9.70 ms per token,   103.10 tokens per second)\n",
      "llama_print_timings:        eval time =   14999.26 ms /   152 runs   (   98.68 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =   25081.44 ms /  1036 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     317.72 ms /  1000 runs   (    0.32 ms per token,  3147.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8576.59 ms /   879 tokens (    9.76 ms per token,   102.49 tokens per second)\n",
      "llama_print_timings:        eval time =  103607.10 ms /   999 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =  123511.08 ms /  1878 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     126.74 ms /   388 runs   (    0.33 ms per token,  3061.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2704.84 ms /   276 tokens (    9.80 ms per token,   102.04 tokens per second)\n",
      "llama_print_timings:        eval time =   35838.82 ms /   387 runs   (   92.61 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =   42441.41 ms /   663 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     4 runs   (    0.38 ms per token,  2621.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6712.13 ms /   691 tokens (    9.71 ms per token,   102.95 tokens per second)\n",
      "llama_print_timings:        eval time =     286.25 ms /     3 runs   (   95.42 ms per token,    10.48 tokens per second)\n",
      "llama_print_timings:       total time =    7045.77 ms /   694 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     182.71 ms /   490 runs   (    0.37 ms per token,  2681.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.79 ms /    33 tokens (   17.78 ms per token,    56.24 tokens per second)\n",
      "llama_print_timings:        eval time =   43875.85 ms /   489 runs   (   89.73 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =   49592.58 ms /   522 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     166.96 ms /   483 runs   (    0.35 ms per token,  2892.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15301.80 ms /  1564 tokens (    9.78 ms per token,   102.21 tokens per second)\n",
      "llama_print_timings:        eval time =   53641.55 ms /   482 runs   (  111.29 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =   74472.89 ms /  2046 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     325.54 ms /  1000 runs   (    0.33 ms per token,  3071.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2739.76 ms /   281 tokens (    9.75 ms per token,   102.56 tokens per second)\n",
      "llama_print_timings:        eval time =   96378.51 ms /   999 runs   (   96.47 ms per token,    10.37 tokens per second)\n",
      "llama_print_timings:       total time =  111126.83 ms /  1280 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     311.08 ms /  1000 runs   (    0.31 ms per token,  3214.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8239.43 ms /   843 tokens (    9.77 ms per token,   102.31 tokens per second)\n",
      "llama_print_timings:        eval time =  102678.22 ms /   999 runs   (  102.78 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =  123159.30 ms /  1842 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     110.86 ms /   337 runs   (    0.33 ms per token,  3039.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3276.88 ms /   330 tokens (    9.93 ms per token,   100.71 tokens per second)\n",
      "llama_print_timings:        eval time =   31292.38 ms /   336 runs   (   93.13 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =   38202.22 ms /   666 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     321.75 ms /  1000 runs   (    0.32 ms per token,  3107.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7585.51 ms /   779 tokens (    9.74 ms per token,   102.70 tokens per second)\n",
      "llama_print_timings:        eval time =  101961.43 ms /   999 runs   (  102.06 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =  121620.56 ms /  1778 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      49.04 ms /   152 runs   (    0.32 ms per token,  3099.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2056.99 ms /   194 tokens (   10.60 ms per token,    94.31 tokens per second)\n",
      "llama_print_timings:        eval time =   13583.24 ms /   151 runs   (   89.96 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =   17223.53 ms /   345 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      78.62 ms /   239 runs   (    0.33 ms per token,  3039.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2675.91 ms /   286 tokens (    9.36 ms per token,   106.88 tokens per second)\n",
      "llama_print_timings:        eval time =   21780.09 ms /   238 runs   (   91.51 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =   27023.65 ms /   524 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     316.51 ms /  1000 runs   (    0.32 ms per token,  3159.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5767.60 ms /   593 tokens (    9.73 ms per token,   102.82 tokens per second)\n",
      "llama_print_timings:        eval time =   99652.27 ms /   999 runs   (   99.75 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =  117581.35 ms /  1592 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      65.23 ms /   201 runs   (    0.32 ms per token,  3081.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3572.51 ms /   369 tokens (    9.68 ms per token,   103.29 tokens per second)\n",
      "llama_print_timings:        eval time =   18449.31 ms /   200 runs   (   92.25 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =   24146.75 ms /   569 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      47.20 ms /   144 runs   (    0.33 ms per token,  3050.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2046.53 ms /   194 tokens (   10.55 ms per token,    94.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12834.83 ms /   143 runs   (   89.75 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =   16376.43 ms /   337 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     117.26 ms /   305 runs   (    0.38 ms per token,  2601.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     316.02 ms /    10 tokens (   31.60 ms per token,    31.64 tokens per second)\n",
      "llama_print_timings:        eval time =   26806.90 ms /   304 runs   (   88.18 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =   30447.07 ms /   314 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      83.50 ms /   251 runs   (    0.33 ms per token,  3005.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3574.00 ms /   366 tokens (    9.77 ms per token,   102.41 tokens per second)\n",
      "llama_print_timings:        eval time =   22970.75 ms /   250 runs   (   91.88 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =   29173.27 ms /   616 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     4 runs   (    0.33 ms per token,  3032.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6942.75 ms /   705 tokens (    9.85 ms per token,   101.54 tokens per second)\n",
      "llama_print_timings:        eval time =     284.47 ms /     3 runs   (   94.82 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =    7273.96 ms /   708 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     149.60 ms /   452 runs   (    0.33 ms per token,  3021.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7554.59 ms /   800 tokens (    9.44 ms per token,   105.90 tokens per second)\n",
      "llama_print_timings:        eval time =   44627.25 ms /   451 runs   (   98.95 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =   57232.23 ms /  1251 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     152.46 ms /   468 runs   (    0.33 ms per token,  3069.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6655.26 ms /   691 tokens (    9.63 ms per token,   103.83 tokens per second)\n",
      "llama_print_timings:        eval time =   45617.06 ms /   467 runs   (   97.68 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =   57530.36 ms /  1158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     316.61 ms /   985 runs   (    0.32 ms per token,  3111.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.07 ms /   190 tokens (    9.30 ms per token,   107.58 tokens per second)\n",
      "llama_print_timings:        eval time =   93224.17 ms /   984 runs   (   94.74 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =  106703.84 ms /  1174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     314.37 ms /  1000 runs   (    0.31 ms per token,  3181.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6654.54 ms /   702 tokens (    9.48 ms per token,   105.49 tokens per second)\n",
      "llama_print_timings:        eval time =  100920.02 ms /   999 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =  119690.61 ms /  1701 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     144.06 ms /   441 runs   (    0.33 ms per token,  3061.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3281.87 ms /   335 tokens (    9.80 ms per token,   102.08 tokens per second)\n",
      "llama_print_timings:        eval time =   41022.24 ms /   440 runs   (   93.23 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =   49244.96 ms /   775 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3149.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11937.22 ms /  1235 tokens (    9.67 ms per token,   103.46 tokens per second)\n",
      "llama_print_timings:        eval time =     101.62 ms /     1 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =   12076.39 ms /  1236 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     117.47 ms /   365 runs   (    0.32 ms per token,  3107.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9821.48 ms /  1006 tokens (    9.76 ms per token,   102.43 tokens per second)\n",
      "llama_print_timings:        eval time =   36722.45 ms /   364 runs   (  100.89 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =   50607.60 ms /  1370 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     149.31 ms /   458 runs   (    0.33 ms per token,  3067.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4197.13 ms /   436 tokens (    9.63 ms per token,   103.88 tokens per second)\n",
      "llama_print_timings:        eval time =   43201.21 ms /   457 runs   (   94.53 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =   52546.87 ms /   893 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      85.23 ms /   258 runs   (    0.33 ms per token,  3027.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.45 ms /   128 tokens (    9.13 ms per token,   109.55 tokens per second)\n",
      "llama_print_timings:        eval time =   23044.05 ms /   257 runs   (   89.67 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =   26944.71 ms /   385 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      64.59 ms /   196 runs   (    0.33 ms per token,  3034.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1473.13 ms /   152 tokens (    9.69 ms per token,   103.18 tokens per second)\n",
      "llama_print_timings:        eval time =   17476.69 ms /   195 runs   (   89.62 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =   21028.26 ms /   347 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      90.63 ms /   279 runs   (    0.32 ms per token,  3078.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.15 ms /   137 tokens (   10.62 ms per token,    94.15 tokens per second)\n",
      "llama_print_timings:        eval time =   25021.04 ms /   278 runs   (   90.00 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =   29406.77 ms /   415 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      77.50 ms /   236 runs   (    0.33 ms per token,  3045.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2364.71 ms /   237 tokens (    9.98 ms per token,   100.22 tokens per second)\n",
      "llama_print_timings:        eval time =   21397.27 ms /   235 runs   (   91.05 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =   26283.88 ms /   472 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      39.78 ms /   124 runs   (    0.32 ms per token,  3116.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1764.31 ms /   183 tokens (    9.64 ms per token,   103.72 tokens per second)\n",
      "llama_print_timings:        eval time =   11011.26 ms /   123 runs   (   89.52 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =   14071.96 ms /   306 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     103.45 ms /   316 runs   (    0.33 ms per token,  3054.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2065.29 ms /   207 tokens (    9.98 ms per token,   100.23 tokens per second)\n",
      "llama_print_timings:        eval time =   28675.50 ms /   315 runs   (   91.03 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =   34178.54 ms /   522 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      41.82 ms /   126 runs   (    0.33 ms per token,  3013.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1770.50 ms /   192 tokens (    9.22 ms per token,   108.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11201.82 ms /   125 runs   (   89.61 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =   14295.64 ms /   317 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      61.53 ms /   192 runs   (    0.32 ms per token,  3120.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2360.42 ms /   233 tokens (   10.13 ms per token,    98.71 tokens per second)\n",
      "llama_print_timings:        eval time =   17307.11 ms /   191 runs   (   90.61 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =   21690.78 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     110.11 ms /   341 runs   (    0.32 ms per token,  3096.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1456.04 ms /   142 tokens (   10.25 ms per token,    97.52 tokens per second)\n",
      "llama_print_timings:        eval time =   30749.36 ms /   340 runs   (   90.44 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =   35958.93 ms /   482 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      62.37 ms /   193 runs   (    0.32 ms per token,  3094.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4208.60 ms /   420 tokens (   10.02 ms per token,    99.80 tokens per second)\n",
      "llama_print_timings:        eval time =   17832.05 ms /   192 runs   (   92.88 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =   24085.87 ms /   612 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      47.51 ms /   149 runs   (    0.32 ms per token,  3136.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.55 ms /   147 tokens (    9.98 ms per token,   100.24 tokens per second)\n",
      "llama_print_timings:        eval time =   13205.96 ms /   148 runs   (   89.23 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =   16251.10 ms /   295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      65.94 ms /   208 runs   (    0.32 ms per token,  3154.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2366.30 ms /   240 tokens (    9.86 ms per token,   101.42 tokens per second)\n",
      "llama_print_timings:        eval time =   18770.02 ms /   207 runs   (   90.68 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =   23371.38 ms /   447 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      30.34 ms /    93 runs   (    0.33 ms per token,  3065.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.35 ms /   124 tokens (    9.53 ms per token,   104.96 tokens per second)\n",
      "llama_print_timings:        eval time =    8153.29 ms /    92 runs   (   88.62 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =   10297.07 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     118.11 ms /   363 runs   (    0.33 ms per token,  3073.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.45 ms /   137 tokens (   10.62 ms per token,    94.13 tokens per second)\n",
      "llama_print_timings:        eval time =   32765.78 ms /   362 runs   (   90.51 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =   38186.92 ms /   499 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      31.39 ms /    98 runs   (    0.32 ms per token,  3122.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3576.44 ms /   382 tokens (    9.36 ms per token,   106.81 tokens per second)\n",
      "llama_print_timings:        eval time =    8898.50 ms /    97 runs   (   91.74 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =   13510.12 ms /   479 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     309.23 ms /  1000 runs   (    0.31 ms per token,  3233.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7875.81 ms /   814 tokens (    9.68 ms per token,   103.35 tokens per second)\n",
      "llama_print_timings:        eval time =  102446.01 ms /   999 runs   (  102.55 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =  122769.09 ms /  1813 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      43.43 ms /   132 runs   (    0.33 ms per token,  3039.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2958.59 ms /   306 tokens (    9.67 ms per token,   103.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11933.27 ms /   131 runs   (   91.09 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =   16253.87 ms /   437 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      83.36 ms /   261 runs   (    0.32 ms per token,  3131.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3279.49 ms /   335 tokens (    9.79 ms per token,   102.15 tokens per second)\n",
      "llama_print_timings:        eval time =   23966.58 ms /   260 runs   (   92.18 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =   30066.75 ms /   595 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     315.75 ms /  1000 runs   (    0.32 ms per token,  3167.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2960.46 ms /   301 tokens (    9.84 ms per token,   101.67 tokens per second)\n",
      "llama_print_timings:        eval time =   96158.66 ms /   999 runs   (   96.25 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =  111226.94 ms /  1300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     306.62 ms /   983 runs   (    0.31 ms per token,  3205.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4579.61 ms /   454 tokens (   10.09 ms per token,    99.13 tokens per second)\n",
      "llama_print_timings:        eval time =   96267.27 ms /   982 runs   (   98.03 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =  112805.24 ms /  1436 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      42.63 ms /   135 runs   (    0.32 ms per token,  3166.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3279.60 ms /   322 tokens (   10.19 ms per token,    98.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12231.16 ms /   134 runs   (   91.28 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =   16941.25 ms /   456 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      60.48 ms /   187 runs   (    0.32 ms per token,  3092.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2661.13 ms /   275 tokens (    9.68 ms per token,   103.34 tokens per second)\n",
      "llama_print_timings:        eval time =   16949.12 ms /   186 runs   (   91.12 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =   21626.16 ms /   461 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     105.74 ms /   329 runs   (    0.32 ms per token,  3111.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3271.58 ms /   323 tokens (   10.13 ms per token,    98.73 tokens per second)\n",
      "llama_print_timings:        eval time =   30349.48 ms /   328 runs   (   92.53 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =   37261.90 ms /   651 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      61.22 ms /   189 runs   (    0.32 ms per token,  3087.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2669.34 ms /   280 tokens (    9.53 ms per token,   104.89 tokens per second)\n",
      "llama_print_timings:        eval time =   17124.87 ms /   188 runs   (   91.09 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =   21833.16 ms /   468 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      34.04 ms /   107 runs   (    0.32 ms per token,  3143.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2962.01 ms /   315 tokens (    9.40 ms per token,   106.35 tokens per second)\n",
      "llama_print_timings:        eval time =    9635.32 ms /   106 runs   (   90.90 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =   13708.67 ms /   421 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      50.05 ms /   155 runs   (    0.32 ms per token,  3096.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4202.08 ms /   425 tokens (    9.89 ms per token,   101.14 tokens per second)\n",
      "llama_print_timings:        eval time =   14252.42 ms /   154 runs   (   92.55 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =   20115.84 ms /   579 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     312.66 ms /  1000 runs   (    0.31 ms per token,  3198.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2658.84 ms /   282 tokens (    9.43 ms per token,   106.06 tokens per second)\n",
      "llama_print_timings:        eval time =   95838.05 ms /   999 runs   (   95.93 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =  110698.55 ms /  1281 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     280.90 ms /   896 runs   (    0.31 ms per token,  3189.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3270.00 ms /   329 tokens (    9.94 ms per token,   100.61 tokens per second)\n",
      "llama_print_timings:        eval time =   85911.00 ms /   895 runs   (   95.99 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =  100020.41 ms /  1224 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      45.83 ms /   143 runs   (    0.32 ms per token,  3120.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2363.52 ms /   239 tokens (    9.89 ms per token,   101.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12811.06 ms /   142 runs   (   90.22 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =   16710.99 ms /   381 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     282.03 ms /   897 runs   (    0.31 ms per token,  3180.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2958.44 ms /   301 tokens (    9.83 ms per token,   101.74 tokens per second)\n",
      "llama_print_timings:        eval time =   85618.54 ms /   896 runs   (   95.56 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =   99460.17 ms /  1197 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      23.10 ms /    70 runs   (    0.33 ms per token,  3030.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5738.13 ms /   591 tokens (    9.71 ms per token,   103.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6490.83 ms /    69 runs   (   94.07 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =   12983.31 ms /   660 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     3 runs   (    0.36 ms per token,  2795.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10061.54 ms /  1035 tokens (    9.72 ms per token,   102.87 tokens per second)\n",
      "llama_print_timings:        eval time =     198.13 ms /     2 runs   (   99.06 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =   10303.52 ms /  1037 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      40.12 ms /   124 runs   (    0.32 ms per token,  3090.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5730.91 ms /   582 tokens (    9.85 ms per token,   101.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11593.91 ms /   123 runs   (   94.26 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =   18658.26 ms /   705 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      32.52 ms /    99 runs   (    0.33 ms per token,  3044.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5723.77 ms /   580 tokens (    9.87 ms per token,   101.33 tokens per second)\n",
      "llama_print_timings:        eval time =    9227.17 ms /    98 runs   (   94.15 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =   15996.90 ms /   678 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      55.07 ms /   172 runs   (    0.32 ms per token,  3123.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1745.85 ms /   164 tokens (   10.65 ms per token,    93.94 tokens per second)\n",
      "llama_print_timings:        eval time =   15338.09 ms /   171 runs   (   89.70 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =   18919.33 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     6 runs   (    0.31 ms per token,  3203.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5745.79 ms /   581 tokens (    9.89 ms per token,   101.12 tokens per second)\n",
      "llama_print_timings:        eval time =     469.06 ms /     5 runs   (   93.81 ms per token,    10.66 tokens per second)\n",
      "llama_print_timings:       total time =    6284.77 ms /   586 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      49.04 ms /   150 runs   (    0.33 ms per token,  3058.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3567.21 ms /   384 tokens (    9.29 ms per token,   107.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13759.45 ms /   149 runs   (   92.35 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =   18918.51 ms /   533 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      42.16 ms /   130 runs   (    0.32 ms per token,  3083.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.68 ms /   202 tokens (   10.20 ms per token,    98.07 tokens per second)\n",
      "llama_print_timings:        eval time =   11598.20 ms /   129 runs   (   89.91 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =   15024.77 ms /   331 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     3 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5744.24 ms /   581 tokens (    9.89 ms per token,   101.14 tokens per second)\n",
      "llama_print_timings:        eval time =     187.41 ms /     2 runs   (   93.70 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =    5970.73 ms /   583 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      33.30 ms /   103 runs   (    0.32 ms per token,  3093.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5729.71 ms /   581 tokens (    9.86 ms per token,   101.40 tokens per second)\n",
      "llama_print_timings:        eval time =    9605.92 ms /   102 runs   (   94.18 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =   16425.48 ms /   683 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     309.79 ms /  1000 runs   (    0.31 ms per token,  3227.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5727.34 ms /   580 tokens (    9.87 ms per token,   101.27 tokens per second)\n",
      "llama_print_timings:        eval time =   99448.82 ms /   999 runs   (   99.55 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =  117592.26 ms /  1579 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      63.45 ms /   194 runs   (    0.33 ms per token,  3057.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2356.28 ms /   233 tokens (   10.11 ms per token,    98.88 tokens per second)\n",
      "llama_print_timings:        eval time =   17464.67 ms /   193 runs   (   90.49 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =   21913.29 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /     3 runs   (    0.36 ms per token,  2752.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5726.61 ms /   581 tokens (    9.86 ms per token,   101.46 tokens per second)\n",
      "llama_print_timings:        eval time =     187.44 ms /     2 runs   (   93.72 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =    5953.76 ms /   583 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      42.59 ms /   135 runs   (    0.32 ms per token,  3169.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5726.01 ms /   581 tokens (    9.86 ms per token,   101.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12651.28 ms /   134 runs   (   94.41 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =   19824.11 ms /   715 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      83.52 ms /   248 runs   (    0.34 ms per token,  2969.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.11 ms /    16 tokens (   19.94 ms per token,    50.14 tokens per second)\n",
      "llama_print_timings:        eval time =   21727.84 ms /   247 runs   (   87.97 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =   24786.98 ms /   263 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     120.06 ms /   375 runs   (    0.32 ms per token,  3123.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6958.48 ms /   735 tokens (    9.47 ms per token,   105.63 tokens per second)\n",
      "llama_print_timings:        eval time =   36256.86 ms /   374 runs   (   96.94 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =   47445.69 ms /  1109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      53.21 ms /   167 runs   (    0.32 ms per token,  3138.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5731.72 ms /   587 tokens (    9.76 ms per token,   102.41 tokens per second)\n",
      "llama_print_timings:        eval time =   15698.77 ms /   166 runs   (   94.57 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =   23253.38 ms /   753 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     8 runs   (    0.31 ms per token,  3231.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6027.22 ms /   611 tokens (    9.86 ms per token,   101.37 tokens per second)\n",
      "llama_print_timings:        eval time =     657.74 ms /     7 runs   (   93.96 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =    6770.04 ms /   618 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     308.60 ms /  1000 runs   (    0.31 ms per token,  3240.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6021.59 ms /   609 tokens (    9.89 ms per token,   101.14 tokens per second)\n",
      "llama_print_timings:        eval time =   99838.19 ms /   999 runs   (   99.94 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =  118300.95 ms /  1608 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     306.79 ms /  1000 runs   (    0.31 ms per token,  3259.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8827.53 ms /   903 tokens (    9.78 ms per token,   102.29 tokens per second)\n",
      "llama_print_timings:        eval time =  103371.06 ms /   999 runs   (  103.47 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =  124858.78 ms /  1902 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      17.23 ms /    53 runs   (    0.33 ms per token,  3076.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5735.41 ms /   581 tokens (    9.87 ms per token,   101.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4883.03 ms /    52 runs   (   93.90 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =   11180.39 ms /   633 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      35.98 ms /   112 runs   (    0.32 ms per token,  3112.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1471.52 ms /   149 tokens (    9.88 ms per token,   101.26 tokens per second)\n",
      "llama_print_timings:        eval time =    9876.58 ms /   111 runs   (   88.98 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =   12557.76 ms /   260 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     306.19 ms /  1000 runs   (    0.31 ms per token,  3265.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5727.15 ms /   581 tokens (    9.86 ms per token,   101.45 tokens per second)\n",
      "llama_print_timings:        eval time =   99495.93 ms /   999 runs   (   99.60 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =  117635.32 ms /  1580 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     4 runs   (    0.34 ms per token,  2906.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5727.80 ms /   580 tokens (    9.88 ms per token,   101.26 tokens per second)\n",
      "llama_print_timings:        eval time =     281.18 ms /     3 runs   (   93.73 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =    6057.52 ms /   583 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      86.30 ms /   273 runs   (    0.32 ms per token,  3163.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6048.22 ms /   638 tokens (    9.48 ms per token,   105.49 tokens per second)\n",
      "llama_print_timings:        eval time =   26093.67 ms /   272 runs   (   95.93 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =   35212.15 ms /   910 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     5 runs   (    0.32 ms per token,  3136.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5733.11 ms /   582 tokens (    9.85 ms per token,   101.52 tokens per second)\n",
      "llama_print_timings:        eval time =     376.17 ms /     4 runs   (   94.04 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =    6166.35 ms /   586 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      56.86 ms /   173 runs   (    0.33 ms per token,  3042.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2074.52 ms /   222 tokens (    9.34 ms per token,   107.01 tokens per second)\n",
      "llama_print_timings:        eval time =   15506.91 ms /   172 runs   (   90.16 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =   19477.56 ms /   394 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     310.98 ms /  1000 runs   (    0.31 ms per token,  3215.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6959.81 ms /   728 tokens (    9.56 ms per token,   104.60 tokens per second)\n",
      "llama_print_timings:        eval time =  101247.20 ms /   999 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =  120865.98 ms /  1727 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     307.16 ms /  1000 runs   (    0.31 ms per token,  3255.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5743.65 ms /   593 tokens (    9.69 ms per token,   103.24 tokens per second)\n",
      "llama_print_timings:        eval time =   99665.97 ms /   999 runs   (   99.77 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =  117967.01 ms /  1592 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      53.25 ms /   167 runs   (    0.32 ms per token,  3136.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1455.20 ms /   139 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =   14806.28 ms /   166 runs   (   89.19 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =   18065.68 ms /   305 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     131.37 ms /   438 runs   (    0.30 ms per token,  3334.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15136.56 ms /  1549 tokens (    9.77 ms per token,   102.33 tokens per second)\n",
      "llama_print_timings:        eval time =   47151.35 ms /   437 runs   (  107.90 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =   67505.64 ms /  1986 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      93.16 ms /   294 runs   (    0.32 ms per token,  3155.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2958.66 ms /   293 tokens (   10.10 ms per token,    99.03 tokens per second)\n",
      "llama_print_timings:        eval time =   26913.65 ms /   293 runs   (   91.86 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =   33160.14 ms /   586 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    24 runs   (    0.31 ms per token,  3208.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3578.28 ms /   358 tokens (   10.00 ms per token,   100.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2096.99 ms /    23 runs   (   91.17 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =    5929.91 ms /   381 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     187.30 ms /   592 runs   (    0.32 ms per token,  3160.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2962.54 ms /   318 tokens (    9.32 ms per token,   107.34 tokens per second)\n",
      "llama_print_timings:        eval time =   55501.27 ms /   591 runs   (   93.91 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =   65791.31 ms /   909 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      61.62 ms /   175 runs   (    0.35 ms per token,  2840.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2362.78 ms /   227 tokens (   10.41 ms per token,    96.07 tokens per second)\n",
      "llama_print_timings:        eval time =   15705.30 ms /   174 runs   (   90.26 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =   19812.18 ms /   401 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     302.00 ms /   897 runs   (    0.34 ms per token,  2970.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2960.46 ms /   300 tokens (    9.87 ms per token,   101.34 tokens per second)\n",
      "llama_print_timings:        eval time =   85574.96 ms /   896 runs   (   95.51 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =   98632.11 ms /  1196 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     142.67 ms /   411 runs   (    0.35 ms per token,  2880.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3267.53 ms /   323 tokens (   10.12 ms per token,    98.85 tokens per second)\n",
      "llama_print_timings:        eval time =   38082.97 ms /   410 runs   (   92.89 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =   45670.32 ms /   733 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     220.54 ms /   635 runs   (    0.35 ms per token,  2879.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3262.05 ms /   322 tokens (   10.13 ms per token,    98.71 tokens per second)\n",
      "llama_print_timings:        eval time =   59810.08 ms /   634 runs   (   94.34 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =   70025.95 ms /   956 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      98.48 ms /   236 runs   (    0.42 ms per token,  2396.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     317.79 ms /    16 tokens (   19.86 ms per token,    50.35 tokens per second)\n",
      "llama_print_timings:        eval time =   20640.42 ms /   235 runs   (   87.83 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =   23341.50 ms /   251 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     298.68 ms /   803 runs   (    0.37 ms per token,  2688.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.49 ms /    17 tokens (   19.03 ms per token,    52.55 tokens per second)\n",
      "llama_print_timings:        eval time =   72989.13 ms /   802 runs   (   91.01 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =   82281.26 ms /   819 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     313.78 ms /   948 runs   (    0.33 ms per token,  3021.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3891.11 ms /   393 tokens (    9.90 ms per token,   101.00 tokens per second)\n",
      "llama_print_timings:        eval time =   91134.53 ms /   947 runs   (   96.23 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =  105840.91 ms /  1340 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     157.83 ms /   455 runs   (    0.35 ms per token,  2882.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3270.29 ms /   337 tokens (    9.70 ms per token,   103.05 tokens per second)\n",
      "llama_print_timings:        eval time =   42351.82 ms /   454 runs   (   93.29 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =   50456.33 ms /   791 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17055.36 ms /  1742 tokens (    9.79 ms per token,   102.14 tokens per second)\n",
      "llama_print_timings:        eval time =     107.77 ms /     1 runs   (  107.77 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =   17208.77 ms /  1743 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     151.23 ms /   442 runs   (    0.34 ms per token,  2922.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9126.75 ms /   949 tokens (    9.62 ms per token,   103.98 tokens per second)\n",
      "llama_print_timings:        eval time =   44409.46 ms /   441 runs   (  100.70 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =   58349.02 ms /  1390 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     142.37 ms /   414 runs   (    0.34 ms per token,  2907.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4892.44 ms /   485 tokens (   10.09 ms per token,    99.13 tokens per second)\n",
      "llama_print_timings:        eval time =   39161.38 ms /   413 runs   (   94.82 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =   48469.69 ms /   898 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     111.48 ms /   327 runs   (    0.34 ms per token,  2933.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3580.70 ms /   383 tokens (    9.35 ms per token,   106.96 tokens per second)\n",
      "llama_print_timings:        eval time =   30385.52 ms /   326 runs   (   93.21 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =   37365.70 ms /   709 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     257.33 ms /   798 runs   (    0.32 ms per token,  3101.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11581.40 ms /  1190 tokens (    9.73 ms per token,   102.75 tokens per second)\n",
      "llama_print_timings:        eval time =   84238.91 ms /   797 runs   (  105.69 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =  105206.15 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     115.77 ms /   339 runs   (    0.34 ms per token,  2928.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2071.51 ms /   222 tokens (    9.33 ms per token,   107.17 tokens per second)\n",
      "llama_print_timings:        eval time =   30831.81 ms /   338 runs   (   91.22 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =   36442.90 ms /   560 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     1 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16647.14 ms /  1710 tokens (    9.74 ms per token,   102.72 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   16683.00 ms /  1711 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     174.68 ms /   491 runs   (    0.36 ms per token,  2810.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     327.24 ms /    21 tokens (   15.58 ms per token,    64.17 tokens per second)\n",
      "llama_print_timings:        eval time =   43700.82 ms /   490 runs   (   89.19 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =   49337.20 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      69.24 ms /   199 runs   (    0.35 ms per token,  2873.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2347.15 ms /   238 tokens (    9.86 ms per token,   101.40 tokens per second)\n",
      "llama_print_timings:        eval time =   17804.58 ms /   198 runs   (   89.92 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =   22147.09 ms /   436 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     146.40 ms /   431 runs   (    0.34 ms per token,  2944.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1742.05 ms /   161 tokens (   10.82 ms per token,    92.42 tokens per second)\n",
      "llama_print_timings:        eval time =   39160.48 ms /   430 runs   (   91.07 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =   45445.50 ms /   591 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     111.30 ms /   321 runs   (    0.35 ms per token,  2884.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1759.86 ms /   182 tokens (    9.67 ms per token,   103.42 tokens per second)\n",
      "llama_print_timings:        eval time =   29011.73 ms /   320 runs   (   90.66 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =   34118.51 ms /   502 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     218.70 ms /   631 runs   (    0.35 ms per token,  2885.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3582.47 ms /   360 tokens (    9.95 ms per token,   100.49 tokens per second)\n",
      "llama_print_timings:        eval time =   59621.81 ms /   630 runs   (   94.64 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =   70207.73 ms /   990 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      84.08 ms /   239 runs   (    0.35 ms per token,  2842.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3571.24 ms /   380 tokens (    9.40 ms per token,   106.41 tokens per second)\n",
      "llama_print_timings:        eval time =   22016.25 ms /   238 runs   (   92.51 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =   28042.94 ms /   618 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     298.55 ms /   893 runs   (    0.33 ms per token,  2991.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2047.76 ms /   194 tokens (   10.56 ms per token,    94.74 tokens per second)\n",
      "llama_print_timings:        eval time =   84032.25 ms /   892 runs   (   94.21 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =   96174.06 ms /  1086 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     143.50 ms /   426 runs   (    0.34 ms per token,  2968.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3571.81 ms /   354 tokens (   10.09 ms per token,    99.11 tokens per second)\n",
      "llama_print_timings:        eval time =   39670.38 ms /   425 runs   (   93.34 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =   47836.61 ms /   779 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     147.78 ms /   425 runs   (    0.35 ms per token,  2875.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2073.87 ms /   214 tokens (    9.69 ms per token,   103.19 tokens per second)\n",
      "llama_print_timings:        eval time =   39913.79 ms /   424 runs   (   94.14 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =   46306.47 ms /   638 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     130.89 ms /   350 runs   (    0.37 ms per token,  2674.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2461.02 ms /   232 tokens (   10.61 ms per token,    94.27 tokens per second)\n",
      "llama_print_timings:        eval time =   33056.07 ms /   349 runs   (   94.72 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =   38922.73 ms /   581 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      83.17 ms /   257 runs   (    0.32 ms per token,  3090.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3342.67 ms /   330 tokens (   10.13 ms per token,    98.72 tokens per second)\n",
      "llama_print_timings:        eval time =   23979.84 ms /   256 runs   (   93.67 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   29543.25 ms /   586 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      86.88 ms /   265 runs   (    0.33 ms per token,  3050.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2410.18 ms /   247 tokens (    9.76 ms per token,   102.48 tokens per second)\n",
      "llama_print_timings:        eval time =   24502.98 ms /   264 runs   (   92.81 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =   29115.83 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     323.73 ms /  1000 runs   (    0.32 ms per token,  3089.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3324.37 ms /   348 tokens (    9.55 ms per token,   104.68 tokens per second)\n",
      "llama_print_timings:        eval time =   98488.78 ms /   999 runs   (   98.59 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =  112210.67 ms /  1347 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     132.08 ms /   410 runs   (    0.32 ms per token,  3104.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2406.38 ms /   251 tokens (    9.59 ms per token,   104.31 tokens per second)\n",
      "llama_print_timings:        eval time =   38437.36 ms /   409 runs   (   93.98 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =   44576.93 ms /   660 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     121.54 ms /   378 runs   (    0.32 ms per token,  3109.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3334.45 ms /   331 tokens (   10.07 ms per token,    99.27 tokens per second)\n",
      "llama_print_timings:        eval time =   35636.27 ms /   377 runs   (   94.53 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =   42263.15 ms /   708 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      42.31 ms /   131 runs   (    0.32 ms per token,  3095.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4300.73 ms /   421 tokens (   10.22 ms per token,    97.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12414.73 ms /   130 runs   (   95.50 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =   17794.58 ms /   551 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     109.50 ms /   335 runs   (    0.33 ms per token,  3059.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3024.30 ms /   294 tokens (   10.29 ms per token,    97.21 tokens per second)\n",
      "llama_print_timings:        eval time =   31333.01 ms /   334 runs   (   93.81 ms per token,    10.66 tokens per second)\n",
      "llama_print_timings:       total time =   37410.78 ms /   628 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     129.13 ms /   393 runs   (    0.33 ms per token,  3043.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2401.90 ms /   238 tokens (   10.09 ms per token,    99.09 tokens per second)\n",
      "llama_print_timings:        eval time =   36619.22 ms /   392 runs   (   93.42 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =   42636.07 ms /   630 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     117.98 ms /   368 runs   (    0.32 ms per token,  3119.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1780.04 ms /   190 tokens (    9.37 ms per token,   106.74 tokens per second)\n",
      "llama_print_timings:        eval time =   34064.97 ms /   367 runs   (   92.82 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =   39091.84 ms /   557 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      73.89 ms /   225 runs   (    0.33 ms per token,  3045.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5246.62 ms /   537 tokens (    9.77 ms per token,   102.35 tokens per second)\n",
      "llama_print_timings:        eval time =   21563.75 ms /   224 runs   (   96.27 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =   28844.80 ms /   761 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     205.16 ms /   629 runs   (    0.33 ms per token,  3065.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1776.95 ms /   190 tokens (    9.35 ms per token,   106.92 tokens per second)\n",
      "llama_print_timings:        eval time =   59305.45 ms /   628 runs   (   94.44 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =   67265.34 ms /   818 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      79.75 ms /   240 runs   (    0.33 ms per token,  3009.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2394.50 ms /   229 tokens (   10.46 ms per token,    95.64 tokens per second)\n",
      "llama_print_timings:        eval time =   22109.84 ms /   239 runs   (   92.51 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =   26688.18 ms /   468 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     231.69 ms /   682 runs   (    0.34 ms per token,  2943.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1777.98 ms /   177 tokens (   10.05 ms per token,    99.55 tokens per second)\n",
      "llama_print_timings:        eval time =   66110.28 ms /   681 runs   (   97.08 ms per token,    10.30 tokens per second)\n",
      "llama_print_timings:       total time =   74938.79 ms /   858 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     153.72 ms /   472 runs   (    0.33 ms per token,  3070.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5925.53 ms /   581 tokens (   10.20 ms per token,    98.05 tokens per second)\n",
      "llama_print_timings:        eval time =   45825.00 ms /   471 runs   (   97.29 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:       total time =   57095.94 ms /  1052 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      81.53 ms /   255 runs   (    0.32 ms per token,  3127.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9516.37 ms /   972 tokens (    9.79 ms per token,   102.14 tokens per second)\n",
      "llama_print_timings:        eval time =   25415.67 ms /   254 runs   (  100.06 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =   37730.84 ms /  1226 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     199.68 ms /   601 runs   (    0.33 ms per token,  3009.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2669.93 ms /   269 tokens (    9.93 ms per token,   100.75 tokens per second)\n",
      "llama_print_timings:        eval time =   56298.82 ms /   600 runs   (   93.83 ms per token,    10.66 tokens per second)\n",
      "llama_print_timings:       total time =   65822.59 ms /   869 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     1 runs   (    0.31 ms per token,  3205.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15865.38 ms /  1627 tokens (    9.75 ms per token,   102.55 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   15903.05 ms /  1628 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     104.37 ms /   321 runs   (    0.33 ms per token,  3075.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2965.56 ms /   317 tokens (    9.36 ms per token,   106.89 tokens per second)\n",
      "llama_print_timings:        eval time =   29540.32 ms /   320 runs   (   92.31 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =   35980.35 ms /   637 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     168.02 ms /   511 runs   (    0.33 ms per token,  3041.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4224.85 ms /   432 tokens (    9.78 ms per token,   102.25 tokens per second)\n",
      "llama_print_timings:        eval time =   48381.22 ms /   510 runs   (   94.87 ms per token,    10.54 tokens per second)\n",
      "llama_print_timings:       total time =   58378.68 ms /   942 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      60.57 ms /   183 runs   (    0.33 ms per token,  3021.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1763.35 ms /   191 tokens (    9.23 ms per token,   108.32 tokens per second)\n",
      "llama_print_timings:        eval time =   16392.45 ms /   182 runs   (   90.07 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =   20069.09 ms /   373 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     366.81 ms /   987 runs   (    0.37 ms per token,  2690.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.20 ms /    26 tokens (   12.78 ms per token,    78.27 tokens per second)\n",
      "llama_print_timings:        eval time =   90891.56 ms /   986 runs   (   92.18 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =  103198.84 ms /  1012 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     328.82 ms /  1000 runs   (    0.33 ms per token,  3041.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3264.62 ms /   321 tokens (   10.17 ms per token,    98.33 tokens per second)\n",
      "llama_print_timings:        eval time =   95580.12 ms /   999 runs   (   95.68 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =  110745.83 ms /  1320 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     117.51 ms /   358 runs   (    0.33 ms per token,  3046.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2663.09 ms /   281 tokens (    9.48 ms per token,   105.52 tokens per second)\n",
      "llama_print_timings:        eval time =   32931.01 ms /   357 runs   (   92.24 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =   39408.80 ms /   638 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      62.58 ms /   188 runs   (    0.33 ms per token,  3004.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2661.92 ms /   273 tokens (    9.75 ms per token,   102.56 tokens per second)\n",
      "llama_print_timings:        eval time =   17005.84 ms /   187 runs   (   90.94 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =   21623.18 ms /   460 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     208.98 ms /   627 runs   (    0.33 ms per token,  3000.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2969.62 ms /   304 tokens (    9.77 ms per token,   102.37 tokens per second)\n",
      "llama_print_timings:        eval time =   58872.82 ms /   626 runs   (   94.05 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =   69043.92 ms /   930 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /     8 runs   (    0.31 ms per token,  3194.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15481.24 ms /  1597 tokens (    9.69 ms per token,   103.16 tokens per second)\n",
      "llama_print_timings:        eval time =     739.99 ms /     7 runs   (  105.71 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =   16332.96 ms /  1604 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     259.66 ms /   743 runs   (    0.35 ms per token,  2861.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     336.44 ms /    30 tokens (   11.21 ms per token,    89.17 tokens per second)\n",
      "llama_print_timings:        eval time =   67335.18 ms /   742 runs   (   90.75 ms per token,    11.02 tokens per second)\n",
      "llama_print_timings:       total time =   76201.27 ms /   772 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     133.62 ms /   397 runs   (    0.34 ms per token,  2971.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3900.30 ms /   392 tokens (    9.95 ms per token,   100.51 tokens per second)\n",
      "llama_print_timings:        eval time =   36815.19 ms /   396 runs   (   92.97 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =   45054.59 ms /   788 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     2 runs   (    0.34 ms per token,  2985.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16078.81 ms /  1644 tokens (    9.78 ms per token,   102.25 tokens per second)\n",
      "llama_print_timings:        eval time =     106.78 ms /     1 runs   (  106.78 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =   16236.75 ms /  1645 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     177.41 ms /   538 runs   (    0.33 ms per token,  3032.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2961.18 ms /   296 tokens (   10.00 ms per token,    99.96 tokens per second)\n",
      "llama_print_timings:        eval time =   50139.63 ms /   537 runs   (   93.37 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =   59144.59 ms /   833 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     172.49 ms /   516 runs   (    0.33 ms per token,  2991.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3898.82 ms /   389 tokens (   10.02 ms per token,    99.77 tokens per second)\n",
      "llama_print_timings:        eval time =   48590.97 ms /   515 runs   (   94.35 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =   58280.73 ms /   904 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     114.26 ms /   346 runs   (    0.33 ms per token,  3028.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2076.28 ms /   221 tokens (    9.39 ms per token,   106.44 tokens per second)\n",
      "llama_print_timings:        eval time =   31487.21 ms /   345 runs   (   91.27 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =   37321.12 ms /   566 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     299.36 ms /   934 runs   (    0.32 ms per token,  3119.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3269.74 ms /   350 tokens (    9.34 ms per token,   107.04 tokens per second)\n",
      "llama_print_timings:        eval time =   89888.25 ms /   933 runs   (   96.34 ms per token,    10.38 tokens per second)\n",
      "llama_print_timings:       total time =  104208.57 ms /  1283 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     133.24 ms /   401 runs   (    0.33 ms per token,  3009.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3283.52 ms /   336 tokens (    9.77 ms per token,   102.33 tokens per second)\n",
      "llama_print_timings:        eval time =   37194.38 ms /   400 runs   (   92.99 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =   44884.88 ms /   736 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     118.14 ms /   358 runs   (    0.33 ms per token,  3030.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2658.75 ms /   262 tokens (   10.15 ms per token,    98.54 tokens per second)\n",
      "llama_print_timings:        eval time =   32797.82 ms /   357 runs   (   91.87 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =   39372.21 ms /   619 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     187.45 ms /   577 runs   (    0.32 ms per token,  3078.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2373.95 ms /   245 tokens (    9.69 ms per token,   103.20 tokens per second)\n",
      "llama_print_timings:        eval time =   53549.78 ms /   576 runs   (   92.97 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =   62480.03 ms /   821 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     240.67 ms /   577 runs   (    0.42 ms per token,  2397.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2965.62 ms /   296 tokens (   10.02 ms per token,    99.81 tokens per second)\n",
      "llama_print_timings:        eval time =   56321.19 ms /   576 runs   (   97.78 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =   66336.09 ms /   872 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     128.07 ms /   222 runs   (    0.58 ms per token,  1733.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5828.40 ms /   592 tokens (    9.85 ms per token,   101.57 tokens per second)\n",
      "llama_print_timings:        eval time =   21153.11 ms /   221 runs   (   95.72 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =   30287.38 ms /   813 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     141.82 ms /   249 runs   (    0.57 ms per token,  1755.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2381.27 ms /   250 tokens (    9.53 ms per token,   104.99 tokens per second)\n",
      "llama_print_timings:        eval time =   22728.47 ms /   248 runs   (   91.65 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =   28844.54 ms /   498 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     126.03 ms /   222 runs   (    0.57 ms per token,  1761.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3278.87 ms /   341 tokens (    9.62 ms per token,   104.00 tokens per second)\n",
      "llama_print_timings:        eval time =   20485.41 ms /   221 runs   (   92.69 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =   27018.30 ms /   562 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     512.73 ms /   922 runs   (    0.56 ms per token,  1798.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3579.86 ms /   381 tokens (    9.40 ms per token,   106.43 tokens per second)\n",
      "llama_print_timings:        eval time =   89486.70 ms /   921 runs   (   97.16 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =  108542.38 ms /  1302 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      98.57 ms /   173 runs   (    0.57 ms per token,  1755.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3581.42 ms /   356 tokens (   10.06 ms per token,    99.40 tokens per second)\n",
      "llama_print_timings:        eval time =   15922.33 ms /   172 runs   (   92.57 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =   22035.44 ms /   528 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /     5 runs   (    0.58 ms per token,  1720.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8209.38 ms /   853 tokens (    9.62 ms per token,   103.91 tokens per second)\n",
      "llama_print_timings:        eval time =     390.79 ms /     4 runs   (   97.70 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =    8683.94 ms /   857 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     179.70 ms /   309 runs   (    0.58 ms per token,  1719.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2962.85 ms /   292 tokens (   10.15 ms per token,    98.55 tokens per second)\n",
      "llama_print_timings:        eval time =   28504.32 ms /   308 runs   (   92.55 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =   36104.69 ms /   600 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     234.97 ms /   411 runs   (    0.57 ms per token,  1749.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3284.95 ms /   332 tokens (    9.89 ms per token,   101.07 tokens per second)\n",
      "llama_print_timings:        eval time =   38401.23 ms /   410 runs   (   93.66 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   48007.54 ms /   742 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     198.94 ms /   342 runs   (    0.58 ms per token,  1719.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.21 ms /   182 tokens (    9.70 ms per token,   103.05 tokens per second)\n",
      "llama_print_timings:        eval time =   31185.73 ms /   341 runs   (   91.45 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =   38125.48 ms /   523 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     552.96 ms /   994 runs   (    0.56 ms per token,  1797.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4914.32 ms /   496 tokens (    9.91 ms per token,   100.93 tokens per second)\n",
      "llama_print_timings:        eval time =   98208.35 ms /   993 runs   (   98.90 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =  120052.67 ms /  1489 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     232.22 ms /   406 runs   (    0.57 ms per token,  1748.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4200.27 ms /   433 tokens (    9.70 ms per token,   103.09 tokens per second)\n",
      "llama_print_timings:        eval time =   38403.73 ms /   405 runs   (   94.82 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =   48881.85 ms /   838 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     151.65 ms /   263 runs   (    0.58 ms per token,  1734.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1751.46 ms /   166 tokens (   10.55 ms per token,    94.78 tokens per second)\n",
      "llama_print_timings:        eval time =   23806.17 ms /   262 runs   (   90.86 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =   29449.52 ms /   428 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     239.24 ms /   413 runs   (    0.58 ms per token,  1726.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2358.99 ms /   226 tokens (   10.44 ms per token,    95.80 tokens per second)\n",
      "llama_print_timings:        eval time =   39956.18 ms /   412 runs   (   96.98 ms per token,    10.31 tokens per second)\n",
      "llama_print_timings:       total time =   48990.29 ms /   638 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     138.03 ms /   243 runs   (    0.57 ms per token,  1760.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3401.73 ms /   326 tokens (   10.43 ms per token,    95.83 tokens per second)\n",
      "llama_print_timings:        eval time =   22615.06 ms /   242 runs   (   93.45 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =   29668.58 ms /   568 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     215.65 ms /   329 runs   (    0.66 ms per token,  1525.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.00 ms /    16 tokens (   19.94 ms per token,    50.16 tokens per second)\n",
      "llama_print_timings:        eval time =   29428.44 ms /   328 runs   (   89.72 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =   34654.55 ms /   344 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     160.37 ms /   274 runs   (    0.59 ms per token,  1708.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3267.92 ms /   345 tokens (    9.47 ms per token,   105.57 tokens per second)\n",
      "llama_print_timings:        eval time =   25225.72 ms /   273 runs   (   92.40 ms per token,    10.82 tokens per second)\n",
      "llama_print_timings:       total time =   32617.91 ms /   618 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     253.12 ms /   440 runs   (    0.58 ms per token,  1738.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4927.65 ms /   492 tokens (   10.02 ms per token,    99.84 tokens per second)\n",
      "llama_print_timings:        eval time =   42040.42 ms /   439 runs   (   95.76 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =   53883.89 ms /   931 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     203.22 ms /   350 runs   (    0.58 ms per token,  1722.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3898.47 ms /   386 tokens (   10.10 ms per token,    99.01 tokens per second)\n",
      "llama_print_timings:        eval time =   32812.90 ms /   349 runs   (   94.02 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =   42054.28 ms /   735 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     141.44 ms /   246 runs   (    0.57 ms per token,  1739.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3581.13 ms /   357 tokens (   10.03 ms per token,    99.69 tokens per second)\n",
      "llama_print_timings:        eval time =   22768.41 ms /   245 runs   (   92.93 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =   30025.38 ms /   602 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15773.93 ms /  1611 tokens (    9.79 ms per token,   102.13 tokens per second)\n",
      "llama_print_timings:        eval time =     106.51 ms /     1 runs   (  106.51 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   15947.21 ms /  1612 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /     5 runs   (    0.57 ms per token,  1740.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7876.57 ms /   813 tokens (    9.69 ms per token,   103.22 tokens per second)\n",
      "llama_print_timings:        eval time =     387.76 ms /     4 runs   (   96.94 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =    8349.29 ms /   817 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     191.61 ms /   333 runs   (    0.58 ms per token,  1737.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2357.34 ms /   233 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =   30534.20 ms /   332 runs   (   91.97 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =   37913.36 ms /   565 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     405.00 ms /   697 runs   (    0.58 ms per token,  1721.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3577.97 ms /   364 tokens (    9.83 ms per token,   101.73 tokens per second)\n",
      "llama_print_timings:        eval time =   66508.18 ms /   696 runs   (   95.56 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =   81591.92 ms /  1060 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     566.49 ms /  1000 runs   (    0.57 ms per token,  1765.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1762.10 ms /   186 tokens (    9.47 ms per token,   105.56 tokens per second)\n",
      "llama_print_timings:        eval time =   95039.56 ms /   999 runs   (   95.13 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =  114036.13 ms /  1185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     435.42 ms /   744 runs   (    0.59 ms per token,  1708.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2366.64 ms /   232 tokens (   10.20 ms per token,    98.03 tokens per second)\n",
      "llama_print_timings:        eval time =   70020.77 ms /   743 runs   (   94.24 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =   84750.06 ms /   975 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     323.43 ms /   553 runs   (    0.58 ms per token,  1709.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2363.58 ms /   238 tokens (    9.93 ms per token,   100.69 tokens per second)\n",
      "llama_print_timings:        eval time =   51586.94 ms /   552 runs   (   93.45 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =   62754.71 ms /   790 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     240.63 ms /   419 runs   (    0.57 ms per token,  1741.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2072.43 ms /   224 tokens (    9.25 ms per token,   108.09 tokens per second)\n",
      "llama_print_timings:        eval time =   38608.78 ms /   418 runs   (   92.37 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =   47209.78 ms /   642 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     214.03 ms /   385 runs   (    0.56 ms per token,  1798.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2357.76 ms /   234 tokens (   10.08 ms per token,    99.25 tokens per second)\n",
      "llama_print_timings:        eval time =   35394.52 ms /   384 runs   (   92.17 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =   43464.13 ms /   618 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     237.03 ms /   417 runs   (    0.57 ms per token,  1759.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6943.86 ms /   705 tokens (    9.85 ms per token,   101.53 tokens per second)\n",
      "llama_print_timings:        eval time =   40785.15 ms /   416 runs   (   98.04 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =   54364.37 ms /  1121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     417.10 ms /   573 runs   (    0.73 ms per token,  1373.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     314.44 ms /    12 tokens (   26.20 ms per token,    38.16 tokens per second)\n",
      "llama_print_timings:        eval time =   51538.26 ms /   572 runs   (   90.10 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =   60999.64 ms /   584 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     257.92 ms /   432 runs   (    0.60 ms per token,  1674.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2963.22 ms /   309 tokens (    9.59 ms per token,   104.28 tokens per second)\n",
      "llama_print_timings:        eval time =   39976.51 ms /   431 runs   (   92.75 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =   49342.75 ms /   740 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     310.10 ms /   544 runs   (    0.57 ms per token,  1754.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11921.77 ms /  1242 tokens (    9.60 ms per token,   104.18 tokens per second)\n",
      "llama_print_timings:        eval time =   57155.28 ms /   543 runs   (  105.26 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   77799.22 ms /  1785 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     178.06 ms /   304 runs   (    0.59 ms per token,  1707.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6024.11 ms /   612 tokens (    9.84 ms per token,   101.59 tokens per second)\n",
      "llama_print_timings:        eval time =   29177.15 ms /   303 runs   (   96.29 ms per token,    10.38 tokens per second)\n",
      "llama_print_timings:       total time =   39596.20 ms /   915 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     110.82 ms /   191 runs   (    0.58 ms per token,  1723.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2371.21 ms /   242 tokens (    9.80 ms per token,   102.06 tokens per second)\n",
      "llama_print_timings:        eval time =   17350.11 ms /   190 runs   (   91.32 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =   22356.26 ms /   432 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     252.42 ms /   420 runs   (    0.60 ms per token,  1663.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2072.56 ms /   214 tokens (    9.68 ms per token,   103.25 tokens per second)\n",
      "llama_print_timings:        eval time =   38640.60 ms /   419 runs   (   92.22 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =   46963.88 ms /   633 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     109.00 ms /   187 runs   (    0.58 ms per token,  1715.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3577.74 ms /   356 tokens (   10.05 ms per token,    99.50 tokens per second)\n",
      "llama_print_timings:        eval time =   17217.82 ms /   186 runs   (   92.57 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =   23424.06 ms /   542 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     265.78 ms /   463 runs   (    0.57 ms per token,  1742.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2074.09 ms /   211 tokens (    9.83 ms per token,   101.73 tokens per second)\n",
      "llama_print_timings:        eval time =   42771.51 ms /   462 runs   (   92.58 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =   51693.09 ms /   673 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     202.62 ms /   341 runs   (    0.59 ms per token,  1682.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3884.11 ms /   411 tokens (    9.45 ms per token,   105.82 tokens per second)\n",
      "llama_print_timings:        eval time =   32000.16 ms /   340 runs   (   94.12 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =   40865.69 ms /   751 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     236.05 ms /   398 runs   (    0.59 ms per token,  1686.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2064.33 ms /   199 tokens (   10.37 ms per token,    96.40 tokens per second)\n",
      "llama_print_timings:        eval time =   36484.10 ms /   397 runs   (   91.90 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =   44419.27 ms /   596 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     148.75 ms /   206 runs   (    0.72 ms per token,  1384.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     316.31 ms /    13 tokens (   24.33 ms per token,    41.10 tokens per second)\n",
      "llama_print_timings:        eval time =   18110.77 ms /   205 runs   (   88.35 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =   21345.37 ms /   218 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     454.21 ms /   788 runs   (    0.58 ms per token,  1734.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2661.11 ms /   288 tokens (    9.24 ms per token,   108.23 tokens per second)\n",
      "llama_print_timings:        eval time =   74392.44 ms /   787 runs   (   94.53 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =   89278.55 ms /  1075 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      89.31 ms /   149 runs   (    0.60 ms per token,  1668.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2360.11 ms /   234 tokens (   10.09 ms per token,    99.15 tokens per second)\n",
      "llama_print_timings:        eval time =   13444.70 ms /   148 runs   (   90.84 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =   17853.27 ms /   382 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     259.11 ms /   435 runs   (    0.60 ms per token,  1678.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2962.57 ms /   296 tokens (   10.01 ms per token,    99.91 tokens per second)\n",
      "llama_print_timings:        eval time =   40480.39 ms /   434 runs   (   93.27 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =   49874.81 ms /   730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     167.82 ms /   288 runs   (    0.58 ms per token,  1716.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1760.95 ms /   181 tokens (    9.73 ms per token,   102.79 tokens per second)\n",
      "llama_print_timings:        eval time =   26180.28 ms /   287 runs   (   91.22 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =   32010.99 ms /   468 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     208.25 ms /   354 runs   (    0.59 ms per token,  1699.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3283.65 ms /   325 tokens (   10.10 ms per token,    98.98 tokens per second)\n",
      "llama_print_timings:        eval time =   32900.09 ms /   353 runs   (   93.20 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =   41341.56 ms /   678 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     323.84 ms /   556 runs   (    0.58 ms per token,  1716.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3567.72 ms /   369 tokens (    9.67 ms per token,   103.43 tokens per second)\n",
      "llama_print_timings:        eval time =   52695.85 ms /   555 runs   (   94.95 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =   64817.13 ms /   924 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     132.29 ms /   226 runs   (    0.59 ms per token,  1708.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2071.65 ms /   224 tokens (    9.25 ms per token,   108.13 tokens per second)\n",
      "llama_print_timings:        eval time =   20513.48 ms /   225 runs   (   91.17 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =   25807.51 ms /   449 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     254.20 ms /   429 runs   (    0.59 ms per token,  1687.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2365.68 ms /   238 tokens (    9.94 ms per token,   100.61 tokens per second)\n",
      "llama_print_timings:        eval time =   39629.87 ms /   428 runs   (   92.59 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =   48375.63 ms /   666 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     568.31 ms /  1000 runs   (    0.57 ms per token,  1759.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7884.23 ms /   831 tokens (    9.49 ms per token,   105.40 tokens per second)\n",
      "llama_print_timings:        eval time =  102920.56 ms /   999 runs   (  103.02 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =  127571.53 ms /  1830 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     147.88 ms /   254 runs   (    0.58 ms per token,  1717.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16087.31 ms /  1660 tokens (    9.69 ms per token,   103.19 tokens per second)\n",
      "llama_print_timings:        eval time =   27498.01 ms /   253 runs   (  108.69 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =   47455.38 ms /  1913 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     112.33 ms /   192 runs   (    0.59 ms per token,  1709.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6047.00 ms /   623 tokens (    9.71 ms per token,   103.03 tokens per second)\n",
      "llama_print_timings:        eval time =   18298.76 ms /   191 runs   (   95.81 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =   27098.23 ms /   814 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     3 runs   (    0.60 ms per token,  1680.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9499.43 ms /   972 tokens (    9.77 ms per token,   102.32 tokens per second)\n",
      "llama_print_timings:        eval time =     197.14 ms /     2 runs   (   98.57 ms per token,    10.15 tokens per second)\n",
      "llama_print_timings:       total time =    9746.61 ms /   974 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      54.61 ms /    92 runs   (    0.59 ms per token,  1684.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11932.40 ms /  1242 tokens (    9.61 ms per token,   104.09 tokens per second)\n",
      "llama_print_timings:        eval time =    9342.00 ms /    91 runs   (  102.66 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =   22609.54 ms /  1333 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     1 runs   (    0.63 ms per token,  1592.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17692.15 ms /  1800 tokens (    9.83 ms per token,   101.74 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   17744.90 ms /  1801 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     153.20 ms /   262 runs   (    0.58 ms per token,  1710.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2652.99 ms /   266 tokens (    9.97 ms per token,   100.26 tokens per second)\n",
      "llama_print_timings:        eval time =   24011.19 ms /   261 runs   (   92.00 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =   30390.59 ms /   527 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     109.92 ms /   185 runs   (    0.59 ms per token,  1683.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2659.35 ms /   282 tokens (    9.43 ms per token,   106.04 tokens per second)\n",
      "llama_print_timings:        eval time =   16860.37 ms /   184 runs   (   91.63 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =   22105.69 ms /   466 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     142.89 ms /   238 runs   (    0.60 ms per token,  1665.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1466.75 ms /   155 tokens (    9.46 ms per token,   105.68 tokens per second)\n",
      "llama_print_timings:        eval time =   21417.67 ms /   237 runs   (   90.37 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =   26262.09 ms /   392 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     274.44 ms /   461 runs   (    0.60 ms per token,  1679.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2359.97 ms /   234 tokens (   10.09 ms per token,    99.15 tokens per second)\n",
      "llama_print_timings:        eval time =   42660.89 ms /   460 runs   (   92.74 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =   51963.75 ms /   694 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      52.62 ms /   171 runs   (    0.31 ms per token,  3249.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1762.47 ms /   181 tokens (    9.74 ms per token,   102.70 tokens per second)\n",
      "llama_print_timings:        eval time =   16801.52 ms /   170 runs   (   98.83 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =   19876.27 ms /   351 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      71.96 ms /   198 runs   (    0.36 ms per token,  2751.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3055.12 ms /   308 tokens (    9.92 ms per token,   100.81 tokens per second)\n",
      "llama_print_timings:        eval time =   18702.71 ms /   197 runs   (   94.94 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =   23542.86 ms /   505 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     229.99 ms /   456 runs   (    0.50 ms per token,  1982.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2789.91 ms /   276 tokens (   10.11 ms per token,    98.93 tokens per second)\n",
      "llama_print_timings:        eval time =   44366.70 ms /   455 runs   (   97.51 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =   52789.41 ms /   731 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     114.57 ms /   252 runs   (    0.45 ms per token,  2199.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3343.45 ms /   343 tokens (    9.75 ms per token,   102.59 tokens per second)\n",
      "llama_print_timings:        eval time =   24446.80 ms /   251 runs   (   97.40 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =   30475.42 ms /   594 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     149.52 ms /   299 runs   (    0.50 ms per token,  1999.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3035.16 ms /   293 tokens (   10.36 ms per token,    96.54 tokens per second)\n",
      "llama_print_timings:        eval time =   28779.57 ms /   298 runs   (   96.58 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =   35422.89 ms /   591 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      88.18 ms /   172 runs   (    0.51 ms per token,  1950.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4666.52 ms /   468 tokens (    9.97 ms per token,   100.29 tokens per second)\n",
      "llama_print_timings:        eval time =   16631.98 ms /   171 runs   (   97.26 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:       total time =   23412.40 ms /   639 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     523.41 ms /  1000 runs   (    0.52 ms per token,  1910.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4701.20 ms /   471 tokens (    9.98 ms per token,   100.19 tokens per second)\n",
      "llama_print_timings:        eval time =  101261.99 ms /   999 runs   (  101.36 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =  120459.38 ms /  1470 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /     2 runs   (    0.62 ms per token,  1611.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10904.38 ms /  1119 tokens (    9.74 ms per token,   102.62 tokens per second)\n",
      "llama_print_timings:        eval time =     102.39 ms /     1 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =   11057.25 ms /  1120 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      85.01 ms /   141 runs   (    0.60 ms per token,  1658.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.23 ms /    15 tokens (   21.55 ms per token,    46.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12624.71 ms /   140 runs   (   90.18 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =   14806.26 ms /   155 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     200.11 ms /   354 runs   (    0.57 ms per token,  1769.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3013.21 ms /   293 tokens (   10.28 ms per token,    97.24 tokens per second)\n",
      "llama_print_timings:        eval time =   32886.78 ms /   353 runs   (   93.16 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =   40911.69 ms /   646 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     196.38 ms /   360 runs   (    0.55 ms per token,  1833.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3341.12 ms /   334 tokens (   10.00 ms per token,    99.97 tokens per second)\n",
      "llama_print_timings:        eval time =   34161.86 ms /   359 runs   (   95.16 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =   42389.42 ms /   693 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     494.92 ms /   760 runs   (    0.65 ms per token,  1535.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     327.90 ms /    15 tokens (   21.86 ms per token,    45.75 tokens per second)\n",
      "llama_print_timings:        eval time =   71581.86 ms /   759 runs   (   94.31 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =   82466.70 ms /   774 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     279.56 ms /   523 runs   (    0.53 ms per token,  1870.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2683.94 ms /   267 tokens (   10.05 ms per token,    99.48 tokens per second)\n",
      "llama_print_timings:        eval time =   49626.78 ms /   522 runs   (   95.07 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =   59851.44 ms /   789 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     508.60 ms /  1000 runs   (    0.51 ms per token,  1966.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1774.89 ms /   175 tokens (   10.14 ms per token,    98.60 tokens per second)\n",
      "llama_print_timings:        eval time =   97347.43 ms /   999 runs   (   97.44 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =  113729.23 ms /  1174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     222.27 ms /   435 runs   (    0.51 ms per token,  1957.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4642.99 ms /   475 tokens (    9.77 ms per token,   102.30 tokens per second)\n",
      "llama_print_timings:        eval time =   42354.05 ms /   434 runs   (   97.59 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =   52670.76 ms /   909 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     521.75 ms /  1000 runs   (    0.52 ms per token,  1916.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4734.36 ms /   456 tokens (   10.38 ms per token,    96.32 tokens per second)\n",
      "llama_print_timings:        eval time =  100018.13 ms /   999 runs   (  100.12 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =  120050.21 ms /  1455 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     540.31 ms /  1000 runs   (    0.54 ms per token,  1850.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2120.02 ms /   200 tokens (   10.60 ms per token,    94.34 tokens per second)\n",
      "llama_print_timings:        eval time =   96558.14 ms /   999 runs   (   96.65 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =  114299.58 ms /  1199 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     198.59 ms /   359 runs   (    0.55 ms per token,  1807.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2084.93 ms /   220 tokens (    9.48 ms per token,   105.52 tokens per second)\n",
      "llama_print_timings:        eval time =   33102.14 ms /   358 runs   (   92.46 ms per token,    10.82 tokens per second)\n",
      "llama_print_timings:       total time =   40281.69 ms /   578 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     309.58 ms /   556 runs   (    0.56 ms per token,  1795.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2977.77 ms /   298 tokens (    9.99 ms per token,   100.07 tokens per second)\n",
      "llama_print_timings:        eval time =   52707.73 ms /   555 runs   (   94.97 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =   64035.83 ms /   853 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     222.57 ms /   394 runs   (    0.56 ms per token,  1770.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2089.66 ms /   218 tokens (    9.59 ms per token,   104.32 tokens per second)\n",
      "llama_print_timings:        eval time =   36408.13 ms /   393 runs   (   92.64 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =   44224.06 ms /   611 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     178.73 ms /   320 runs   (    0.56 ms per token,  1790.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3595.54 ms /   367 tokens (    9.80 ms per token,   102.07 tokens per second)\n",
      "llama_print_timings:        eval time =   30008.39 ms /   319 runs   (   94.07 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =   38196.94 ms /   686 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     152.66 ms /   270 runs   (    0.57 ms per token,  1768.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3578.04 ms /   370 tokens (    9.67 ms per token,   103.41 tokens per second)\n",
      "llama_print_timings:        eval time =   25187.85 ms /   269 runs   (   93.64 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   32627.11 ms /   639 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     489.92 ms /   886 runs   (    0.55 ms per token,  1808.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1761.13 ms /   180 tokens (    9.78 ms per token,   102.21 tokens per second)\n",
      "llama_print_timings:        eval time =   84766.06 ms /   885 runs   (   95.78 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =  100168.69 ms /  1065 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     162.91 ms /   292 runs   (    0.56 ms per token,  1792.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3040.25 ms /   308 tokens (    9.87 ms per token,   101.31 tokens per second)\n",
      "llama_print_timings:        eval time =   27329.86 ms /   291 runs   (   93.92 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =   34406.11 ms /   599 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     537.27 ms /  1000 runs   (    0.54 ms per token,  1861.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2406.93 ms /   225 tokens (   10.70 ms per token,    93.48 tokens per second)\n",
      "llama_print_timings:        eval time =   97748.88 ms /   999 runs   (   97.85 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =  115434.19 ms /  1224 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     202.94 ms /   369 runs   (    0.55 ms per token,  1818.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3601.29 ms /   355 tokens (   10.14 ms per token,    98.58 tokens per second)\n",
      "llama_print_timings:        eval time =   34865.43 ms /   368 runs   (   94.74 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =   43783.65 ms /   723 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     170.58 ms /   319 runs   (    0.53 ms per token,  1870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4682.52 ms /   478 tokens (    9.80 ms per token,   102.08 tokens per second)\n",
      "llama_print_timings:        eval time =   30752.89 ms /   318 runs   (   96.71 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =   39731.75 ms /   796 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     516.35 ms /  1000 runs   (    0.52 ms per token,  1936.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2370.88 ms /   237 tokens (   10.00 ms per token,    99.96 tokens per second)\n",
      "llama_print_timings:        eval time =   99502.45 ms /   999 runs   (   99.60 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =  116303.49 ms /  1236 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     524.33 ms /  1000 runs   (    0.52 ms per token,  1907.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5695.24 ms /   569 tokens (   10.01 ms per token,    99.91 tokens per second)\n",
      "llama_print_timings:        eval time =  100879.18 ms /   999 runs   (  100.98 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =  122876.63 ms /  1568 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     241.36 ms /   424 runs   (    0.57 ms per token,  1756.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3969.95 ms /   409 tokens (    9.71 ms per token,   103.02 tokens per second)\n",
      "llama_print_timings:        eval time =   40201.93 ms /   423 runs   (   95.04 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =   50820.09 ms /   832 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      18.32 ms /    24 runs   (    0.76 ms per token,  1310.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     331.34 ms /    23 tokens (   14.41 ms per token,    69.42 tokens per second)\n",
      "llama_print_timings:        eval time =    2031.97 ms /    23 runs   (   88.35 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =    2699.48 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19353.81 ms /  1980 tokens (    9.77 ms per token,   102.31 tokens per second)\n",
      "llama_print_timings:        eval time =     110.27 ms /     1 runs   (  110.27 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =   19527.46 ms /  1981 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     196.96 ms /   347 runs   (    0.57 ms per token,  1761.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6961.87 ms /   708 tokens (    9.83 ms per token,   101.70 tokens per second)\n",
      "llama_print_timings:        eval time =   33932.99 ms /   346 runs   (   98.07 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =   46106.53 ms /  1054 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     336.43 ms /   570 runs   (    0.59 ms per token,  1694.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.98 ms /    16 tokens (   20.00 ms per token,    50.00 tokens per second)\n",
      "llama_print_timings:        eval time =   51444.90 ms /   569 runs   (   90.41 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =   60520.35 ms /   585 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     246.90 ms /   415 runs   (    0.59 ms per token,  1680.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     329.12 ms /    22 tokens (   14.96 ms per token,    66.85 tokens per second)\n",
      "llama_print_timings:        eval time =   37105.54 ms /   414 runs   (   89.63 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =   43527.53 ms /   436 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     312.41 ms /   424 runs   (    0.74 ms per token,  1357.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     318.57 ms /    14 tokens (   22.76 ms per token,    43.95 tokens per second)\n",
      "llama_print_timings:        eval time =   37927.98 ms /   423 runs   (   89.66 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =   44476.38 ms /   437 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     101.38 ms /   180 runs   (    0.56 ms per token,  1775.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13856.73 ms /  1421 tokens (    9.75 ms per token,   102.55 tokens per second)\n",
      "llama_print_timings:        eval time =   18776.28 ms /   179 runs   (  104.90 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   35279.67 ms /  1600 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     354.97 ms /   630 runs   (    0.56 ms per token,  1774.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13170.74 ms /  1358 tokens (    9.70 ms per token,   103.11 tokens per second)\n",
      "llama_print_timings:        eval time =   67562.37 ms /   629 runs   (  107.41 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =   91156.39 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /     1 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19378.76 ms /  1955 tokens (    9.91 ms per token,   100.88 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   19430.55 ms /  1956 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     260.10 ms /   446 runs   (    0.58 ms per token,  1714.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13146.00 ms /  1369 tokens (    9.60 ms per token,   104.14 tokens per second)\n",
      "llama_print_timings:        eval time =   47364.08 ms /   445 runs   (  106.44 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =   67469.47 ms /  1814 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     2 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13856.86 ms /  1434 tokens (    9.66 ms per token,   103.49 tokens per second)\n",
      "llama_print_timings:        eval time =     104.88 ms /     1 runs   (  104.88 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   14014.44 ms /  1435 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      84.77 ms /   141 runs   (    0.60 ms per token,  1663.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13664.99 ms /  1284 tokens (   10.64 ms per token,    93.96 tokens per second)\n",
      "llama_print_timings:        eval time =   15538.25 ms /   140 runs   (  110.99 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =   31431.37 ms /  1424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     361.25 ms /   493 runs   (    0.73 ms per token,  1364.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     324.96 ms /    15 tokens (   21.66 ms per token,    46.16 tokens per second)\n",
      "llama_print_timings:        eval time =   44722.46 ms /   492 runs   (   90.90 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =   52361.63 ms /   507 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     175.11 ms /   305 runs   (    0.57 ms per token,  1741.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4252.73 ms /   439 tokens (    9.69 ms per token,   103.23 tokens per second)\n",
      "llama_print_timings:        eval time =   28536.15 ms /   304 runs   (   93.87 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =   37213.00 ms /   743 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     122.57 ms /   209 runs   (    0.59 ms per token,  1705.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2076.14 ms /   210 tokens (    9.89 ms per token,   101.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18942.88 ms /   208 runs   (   91.07 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =   23989.14 ms /   418 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     156.04 ms /   266 runs   (    0.59 ms per token,  1704.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3896.30 ms /   403 tokens (    9.67 ms per token,   103.43 tokens per second)\n",
      "llama_print_timings:        eval time =   24904.12 ms /   265 runs   (   93.98 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =   32603.12 ms /   668 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     188.87 ms /   334 runs   (    0.57 ms per token,  1768.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16117.49 ms /  1653 tokens (    9.75 ms per token,   102.56 tokens per second)\n",
      "llama_print_timings:        eval time =   36301.19 ms /   333 runs   (  109.01 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =   57639.50 ms /  1986 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     1 runs   (    0.56 ms per token,  1773.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16777.56 ms /  1722 tokens (    9.74 ms per token,   102.64 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   16827.52 ms /  1723 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     6 runs   (    0.60 ms per token,  1662.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6026.19 ms /   610 tokens (    9.88 ms per token,   101.22 tokens per second)\n",
      "llama_print_timings:        eval time =     472.58 ms /     5 runs   (   94.52 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =    6591.16 ms /   615 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     249.51 ms /   353 runs   (    0.71 ms per token,  1414.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     317.72 ms /    14 tokens (   22.69 ms per token,    44.06 tokens per second)\n",
      "llama_print_timings:        eval time =   31348.03 ms /   352 runs   (   89.06 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =   36790.20 ms /   366 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     223.03 ms /   386 runs   (    0.58 ms per token,  1730.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12550.34 ms /  1296 tokens (    9.68 ms per token,   103.26 tokens per second)\n",
      "llama_print_timings:        eval time =   40242.47 ms /   385 runs   (  104.53 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =   58784.52 ms /  1681 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     565.25 ms /  1000 runs   (    0.57 ms per token,  1769.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3275.78 ms /   349 tokens (    9.39 ms per token,   106.54 tokens per second)\n",
      "llama_print_timings:        eval time =   97093.66 ms /   999 runs   (   97.19 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =  117102.23 ms /  1348 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     146.65 ms /   235 runs   (    0.62 ms per token,  1602.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     315.30 ms /    11 tokens (   28.66 ms per token,    34.89 tokens per second)\n",
      "llama_print_timings:        eval time =   20760.59 ms /   234 runs   (   88.72 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =   24449.51 ms /   245 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     233.18 ms /   385 runs   (    0.61 ms per token,  1651.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     318.32 ms /    13 tokens (   24.49 ms per token,    40.84 tokens per second)\n",
      "llama_print_timings:        eval time =   34283.03 ms /   384 runs   (   89.28 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =   40267.97 ms /   397 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     328.76 ms /   436 runs   (    0.75 ms per token,  1326.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     313.17 ms /     9 tokens (   34.80 ms per token,    28.74 tokens per second)\n",
      "llama_print_timings:        eval time =   38912.60 ms /   435 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =   45758.93 ms /   444 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     262.71 ms /   422 runs   (    0.62 ms per token,  1606.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     312.62 ms /     7 tokens (   44.66 ms per token,    22.39 tokens per second)\n",
      "llama_print_timings:        eval time =   37610.04 ms /   421 runs   (   89.34 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =   44219.86 ms /   428 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     247.45 ms /   415 runs   (    0.60 ms per token,  1677.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.91 ms /    19 tokens (   17.15 ms per token,    58.30 tokens per second)\n",
      "llama_print_timings:        eval time =   37032.68 ms /   414 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =   43421.76 ms /   433 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     302.75 ms /   483 runs   (    0.63 ms per token,  1595.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.32 ms /    16 tokens (   20.08 ms per token,    49.79 tokens per second)\n",
      "llama_print_timings:        eval time =   43285.69 ms /   482 runs   (   89.80 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =   50818.99 ms /   498 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.57 ms per token,  1743.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19399.00 ms /  1961 tokens (    9.89 ms per token,   101.09 tokens per second)\n",
      "llama_print_timings:        eval time =     109.98 ms /     1 runs   (  109.98 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =   19572.64 ms /  1962 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     293.55 ms /   504 runs   (    0.58 ms per token,  1716.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3579.11 ms /   365 tokens (    9.81 ms per token,   101.98 tokens per second)\n",
      "llama_print_timings:        eval time =   47546.72 ms /   503 runs   (   94.53 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =   58863.23 ms /   868 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     123.42 ms /   208 runs   (    0.59 ms per token,  1685.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3579.87 ms /   364 tokens (    9.83 ms per token,   101.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19220.17 ms /   207 runs   (   92.85 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =   25769.02 ms /   571 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     250.24 ms /   432 runs   (    0.58 ms per token,  1726.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2964.97 ms /   308 tokens (    9.63 ms per token,   103.88 tokens per second)\n",
      "llama_print_timings:        eval time =   40313.01 ms /   431 runs   (   93.53 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =   49799.50 ms /   739 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     316.72 ms /   549 runs   (    0.58 ms per token,  1733.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3572.74 ms /   371 tokens (    9.63 ms per token,   103.84 tokens per second)\n",
      "llama_print_timings:        eval time =   51995.21 ms /   548 runs   (   94.88 ms per token,    10.54 tokens per second)\n",
      "llama_print_timings:       total time =   64156.56 ms /   919 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /     3 runs   (    0.75 ms per token,  1330.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19383.74 ms /  1962 tokens (    9.88 ms per token,   101.22 tokens per second)\n",
      "llama_print_timings:        eval time =     221.76 ms /     2 runs   (  110.88 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =   19688.63 ms /  1964 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     255.53 ms /   448 runs   (    0.57 ms per token,  1753.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4540.91 ms /   452 tokens (   10.05 ms per token,    99.54 tokens per second)\n",
      "llama_print_timings:        eval time =   42562.31 ms /   447 runs   (   95.22 ms per token,    10.50 tokens per second)\n",
      "llama_print_timings:       total time =   53924.52 ms /   899 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     236.18 ms /   412 runs   (    0.57 ms per token,  1744.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3888.99 ms /   402 tokens (    9.67 ms per token,   103.37 tokens per second)\n",
      "llama_print_timings:        eval time =   38804.76 ms /   411 runs   (   94.42 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =   48929.15 ms /   813 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18952.45 ms /  1945 tokens (    9.74 ms per token,   102.63 tokens per second)\n",
      "llama_print_timings:        eval time =     110.45 ms /     1 runs   (  110.45 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =   19129.36 ms /  1946 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     363.14 ms /   628 runs   (    0.58 ms per token,  1729.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9156.35 ms /   937 tokens (    9.77 ms per token,   102.33 tokens per second)\n",
      "llama_print_timings:        eval time =   64065.73 ms /   627 runs   (  102.18 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =   83371.62 ms /  1564 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     566.10 ms /  1000 runs   (    0.57 ms per token,  1766.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9150.18 ms /   933 tokens (    9.81 ms per token,   101.97 tokens per second)\n",
      "llama_print_timings:        eval time =  104062.12 ms /   999 runs   (  104.17 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =  130251.91 ms /  1932 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     108.79 ms /   200 runs   (    0.54 ms per token,  1838.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2963.12 ms /   303 tokens (    9.78 ms per token,   102.26 tokens per second)\n",
      "llama_print_timings:        eval time =   18620.08 ms /   199 runs   (   93.57 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =   24302.61 ms /   502 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     205.58 ms /   352 runs   (    0.58 ms per token,  1712.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3589.99 ms /   368 tokens (    9.76 ms per token,   102.51 tokens per second)\n",
      "llama_print_timings:        eval time =   32875.08 ms /   351 runs   (   93.66 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   41724.14 ms /   719 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     1 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12878.55 ms /  1333 tokens (    9.66 ms per token,   103.51 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   12916.24 ms /  1334 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /     4 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14481.95 ms /  1491 tokens (    9.71 ms per token,   102.96 tokens per second)\n",
      "llama_print_timings:        eval time =     315.65 ms /     3 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   14881.06 ms /  1494 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     125.10 ms /   213 runs   (    0.59 ms per token,  1702.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2649.42 ms /   258 tokens (   10.27 ms per token,    97.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19480.17 ms /   212 runs   (   91.89 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =   25149.20 ms /   470 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      93.19 ms /   161 runs   (    0.58 ms per token,  1727.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2072.86 ms /   220 tokens (    9.42 ms per token,   106.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14553.90 ms /   160 runs   (   90.96 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =   18918.17 ms /   380 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     191.92 ms /   332 runs   (    0.58 ms per token,  1729.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2653.01 ms /   266 tokens (    9.97 ms per token,   100.26 tokens per second)\n",
      "llama_print_timings:        eval time =   30542.53 ms /   331 runs   (   92.27 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =   38140.44 ms /   597 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     318.33 ms /   563 runs   (    0.57 ms per token,  1768.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7867.72 ms /   810 tokens (    9.71 ms per token,   102.95 tokens per second)\n",
      "llama_print_timings:        eval time =   56316.61 ms /   562 runs   (  100.21 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =   73295.48 ms /  1372 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     555.95 ms /  1000 runs   (    0.56 ms per token,  1798.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8184.37 ms /   858 tokens (    9.54 ms per token,   104.83 tokens per second)\n",
      "llama_print_timings:        eval time =  103179.81 ms /   999 runs   (  103.28 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =  128490.01 ms /  1857 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     574.32 ms /  1000 runs   (    0.57 ms per token,  1741.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8499.83 ms /   868 tokens (    9.79 ms per token,   102.12 tokens per second)\n",
      "llama_print_timings:        eval time =  103284.75 ms /   999 runs   (  103.39 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =  128948.94 ms /  1867 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     268.41 ms /   457 runs   (    0.59 ms per token,  1702.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2664.56 ms /   264 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =   42397.94 ms /   456 runs   (   92.98 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =   52190.93 ms /   720 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1668.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13844.96 ms /  1422 tokens (    9.74 ms per token,   102.71 tokens per second)\n",
      "llama_print_timings:        eval time =     624.86 ms /     6 runs   (  104.14 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =   14594.78 ms /  1428 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19014.50 ms /  1951 tokens (    9.75 ms per token,   102.61 tokens per second)\n",
      "llama_print_timings:        eval time =     110.34 ms /     1 runs   (  110.34 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =   19196.58 ms /  1952 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     1 runs   (    0.59 ms per token,  1689.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19387.91 ms /  1953 tokens (    9.93 ms per token,   100.73 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   19439.91 ms /  1954 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     330.46 ms /   571 runs   (    0.58 ms per token,  1727.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13808.64 ms /  1417 tokens (    9.74 ms per token,   102.62 tokens per second)\n",
      "llama_print_timings:        eval time =   61275.18 ms /   570 runs   (  107.50 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =   84268.83 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     310.25 ms /   680 runs   (    0.46 ms per token,  2191.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12539.79 ms /  1308 tokens (    9.59 ms per token,   104.31 tokens per second)\n",
      "llama_print_timings:        eval time =   75794.43 ms /   679 runs   (  111.63 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =   97075.44 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     210.79 ms /   329 runs   (    0.64 ms per token,  1560.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.23 ms /    14 tokens (   23.23 ms per token,    43.05 tokens per second)\n",
      "llama_print_timings:        eval time =   30356.82 ms /   328 runs   (   92.55 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =   34487.54 ms /   342 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     123.41 ms /   239 runs   (    0.52 ms per token,  1936.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8305.84 ms /   815 tokens (   10.19 ms per token,    98.12 tokens per second)\n",
      "llama_print_timings:        eval time =   24666.28 ms /   238 runs   (  103.64 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =   35807.50 ms /  1053 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =      28.22 ms /    50 runs   (    0.56 ms per token,  1771.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19956.42 ms /  1938 tokens (   10.30 ms per token,    97.11 tokens per second)\n",
      "llama_print_timings:        eval time =    5543.21 ms /    49 runs   (  113.13 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =   26222.75 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     445.08 ms /   846 runs   (    0.53 ms per token,  1900.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2409.38 ms /   253 tokens (    9.52 ms per token,   105.01 tokens per second)\n",
      "llama_print_timings:        eval time =   82648.33 ms /   845 runs   (   97.81 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =   97038.02 ms /  1098 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     245.57 ms /   490 runs   (    0.50 ms per token,  1995.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7891.27 ms /   799 tokens (    9.88 ms per token,   101.25 tokens per second)\n",
      "llama_print_timings:        eval time =   50317.91 ms /   489 runs   (  102.90 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =   64418.24 ms /  1288 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     211.72 ms /   382 runs   (    0.55 ms per token,  1804.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4248.60 ms /   419 tokens (   10.14 ms per token,    98.62 tokens per second)\n",
      "llama_print_timings:        eval time =   36316.52 ms /   381 runs   (   95.32 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =   46147.34 ms /   800 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     3 runs   (    0.57 ms per token,  1758.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7935.54 ms /   831 tokens (    9.55 ms per token,   104.72 tokens per second)\n",
      "llama_print_timings:        eval time =     195.44 ms /     2 runs   (   97.72 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =    8180.15 ms /   833 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     303.14 ms /   518 runs   (    0.59 ms per token,  1708.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2680.40 ms /   279 tokens (    9.61 ms per token,   104.09 tokens per second)\n",
      "llama_print_timings:        eval time =   48590.22 ms /   517 runs   (   93.98 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =   59157.90 ms /   796 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     352.24 ms /   617 runs   (    0.57 ms per token,  1751.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3598.25 ms /   359 tokens (   10.02 ms per token,    99.77 tokens per second)\n",
      "llama_print_timings:        eval time =   58809.51 ms /   616 runs   (   95.47 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =   72017.42 ms /   975 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     602.76 ms /   820 runs   (    0.74 ms per token,  1360.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     331.10 ms /    24 tokens (   13.80 ms per token,    72.49 tokens per second)\n",
      "llama_print_timings:        eval time =   75302.98 ms /   819 runs   (   91.95 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =   89090.67 ms /   843 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     327.49 ms /   557 runs   (    0.59 ms per token,  1700.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2965.61 ms /   306 tokens (    9.69 ms per token,   103.18 tokens per second)\n",
      "llama_print_timings:        eval time =   52074.63 ms /   556 runs   (   93.66 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   63545.12 ms /   862 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     265.21 ms /   458 runs   (    0.58 ms per token,  1726.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14912.30 ms /  1530 tokens (    9.75 ms per token,   102.60 tokens per second)\n",
      "llama_print_timings:        eval time =   49661.41 ms /   457 runs   (  108.67 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =   71716.81 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     142.93 ms /   247 runs   (    0.58 ms per token,  1728.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17198.91 ms /  1741 tokens (    9.88 ms per token,   101.23 tokens per second)\n",
      "llama_print_timings:        eval time =   27091.56 ms /   246 runs   (  110.13 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =   47969.45 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     408.18 ms /   709 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12336.61 ms /  1279 tokens (    9.65 ms per token,   103.68 tokens per second)\n",
      "llama_print_timings:        eval time =   75851.68 ms /   708 runs   (  107.14 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =   99841.70 ms /  1987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    11 runs   (    0.56 ms per token,  1771.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7615.78 ms /   775 tokens (    9.83 ms per token,   101.76 tokens per second)\n",
      "llama_print_timings:        eval time =     979.56 ms /    10 runs   (   97.96 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =    8749.62 ms /   785 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     295.47 ms /   498 runs   (    0.59 ms per token,  1685.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9209.62 ms /   929 tokens (    9.91 ms per token,   100.87 tokens per second)\n",
      "llama_print_timings:        eval time =   52888.11 ms /   497 runs   (  106.41 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =   70001.42 ms /  1426 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     206.41 ms /   358 runs   (    0.58 ms per token,  1734.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3321.76 ms /   344 tokens (    9.66 ms per token,   103.56 tokens per second)\n",
      "llama_print_timings:        eval time =   33419.09 ms /   357 runs   (   93.61 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   41994.26 ms /   701 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    3414.05 ms\n",
      "llama_print_timings:      sample time =     420.73 ms /   578 runs   (    0.73 ms per token,  1373.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.08 ms /    20 tokens (   16.25 ms per token,    61.52 tokens per second)\n",
      "llama_print_timings:        eval time =   52503.83 ms /   577 runs   (   90.99 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =   61627.94 ms /   597 tokens\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "responses = []\n",
    "i = 0\n",
    "for question in df_test['Question Text'].values.tolist():\n",
    "    df_book_results, df_question_results = search_content(query=question, df_sentances=df_booklet, df_questions= df_train,\n",
    "                                       book_index=fastIndex, question_index=fastIndex_train, embedder=embedding_model, k=5)\n",
    "    response = get_response(text=question, llm=llm_model, df_book_matches=df_book_results, df_question_matches=df_question_results)\n",
    "    response[\"keywords\"] = extract_keyword(str(df_book_results['text'].values + df_question_results['Question Answer'].values), top_n=5)\n",
    "    responses.append(response)\n",
    "\n",
    "df_responses = pd.DataFrame(responses)\n",
    "df_responses['ID'] = df_test['ID']\n",
    "df_responses['Question'] = df_test['Question Text']\n",
    "# df_responses[[\"Question\", \"question_answer\", \"reference_document\", \"paragraph(s)_number\", \"keywords\", \"ID\"]].to_csv(pwd + \"/data/data/answers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submissoion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses.columns = ['question_answer', 'reference_document', 'paragraph(s)_number', 'keywords', 'ID', 'Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses[\"question_answer\"] = [\"Could not retrieve answer\" if answer == \"\" else answer for answer in df_responses[\"question_answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.melt(df_responses, id_vars=['ID'], value_vars=['question_answer', 'reference_document', 'paragraph(s)_number', \"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['ID'] = df_submission['ID'] + '_' + df_submission['variable']\n",
    "df_submission.columns = [\"ID\", \"variable\", \"Target\"]\n",
    "df_submission = df_submission[['ID', \"Target\"]].set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(pwd + \"/data/submissions/submission_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 ('zindi_llm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1b94373ed21143aa54ae29a501b4c41cca272fcc00b21ffb9f53282b803de8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
