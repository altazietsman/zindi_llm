{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/zindi_llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import torch\n",
    "from utils.embeddings import Embedder\n",
    "from utils.preprocess import create_sentance_booklet, create_faise_index\n",
    "import faiss\n",
    "from utils.utils import search_content, read_booklets, retrieve_booklet_text, clean_text, reformat_abbreviations\n",
    "from models.ollama import Ollama\n",
    "from utils.response_generator import get_response, extract_keyword, get_paragraph_info, find_matching_paragraphs\n",
    "from rouge_score import rouge_scorer\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silly Mac that forces me to change the environmental variable to prevent issues running transformers\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd  = str(pathlib.Path().cwd().parent.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet = read_booklets((pwd + \"/data/data/booklets/\"))\n",
    "df_train = pd.read_csv(pwd + \"/data/data/Train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Clean some of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet['cleanText'] = df_booklet['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data\n",
    "We will refromat the abbreviation text. We will then also remove any other unicode characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = df_booklet[df_booklet['text'].str.lstrip().str.startswith(\"AAR\")].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indx in abbreviations:\n",
    "    abrv_dict = reformat_abbreviations(df_booklet.iloc[indx]['text'])\n",
    "    new_abrv_text = [(key +\" : \"+ value) for key, value in  abrv_dict.items()]\n",
    "    abrv_df = pd.DataFrame({\"text\": new_abrv_text,\n",
    "                            \"cleanText\": new_abrv_text})\n",
    "    abrv_df['index'] = df_booklet.iloc[indx]['index']\n",
    "    abrv_df['book'] = df_booklet.iloc[indx]['book']\n",
    "    df_booklet = pd.concat([df_booklet, abrv_df[df_booklet.drop(\"level_0\", axis=1).columns]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove abbreviation indexes\n",
    "df_booklet = df_booklet.drop(abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all empty strings\n",
    "df_booklet = df_booklet[df_booklet['cleanText'] != \" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet = df_booklet.drop(['level_0', 'text'], axis=1)\n",
    "df_booklet.columns = ['paragraph',  'book', 'cleanText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed and Create Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(dataset: pd.DataFrame, chunk_size: int=500, chunk_overlap: int=10) -> list:\n",
    "    \"\"\"\n",
    "    Create chunks from the dataset\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): Dataset\n",
    "        chunk_size (int): Chunk size\n",
    "        chunk_overlap (int): Chunk overlap\n",
    "\n",
    "    Returns:\n",
    "        list: List of chunks\n",
    "    \"\"\"\n",
    "    text_chunks = DataFrameLoader(\n",
    "        dataset, page_content_column=\"cleanText\"\n",
    "    ).load_and_split(\n",
    "        text_splitter=RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return text_chunks\n",
    "\n",
    "\n",
    "def create_or_get_vector_store(chunks: list, recreate_embeddings=False) -> FAISS:\n",
    "    \"\"\"\n",
    "    Create or get vector store\n",
    "\n",
    "    Args:\n",
    "        chunks (list): List of chunks\n",
    "\n",
    "    Returns:\n",
    "        FAISS: Vector store\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "    )\n",
    "    if not os.path.exists(\"./db\") or recreate_embeddings:\n",
    "        print(\"CREATING DB\")\n",
    "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "        vectorstore.save_local(\"./db\")\n",
    "    else:\n",
    "        # print(\"LOADING DB\")\n",
    "        vectorstore = FAISS.load_local(\"./db\", embeddings)\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def embed_booklets(df, recreate_embeddings=False):\n",
    "    chunks = create_chunks(df, 2000, 0)\n",
    "    vector_store = create_or_get_vector_store(chunks, recreate_embeddings=recreate_embeddings)\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet['cleanText'] = [x+\" \" for x in df_booklet['cleanText']]\n",
    "df_booklet.sort_values(by=['book', 'paragraph'], inplace=True)\n",
    "docs = \"\".join(df_booklet['cleanText'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet['len'] = [len(text) for text in df_booklet['cleanText'].astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new splits \n",
    "sum = 0\n",
    "counter = 0\n",
    "splits = []\n",
    "\n",
    "for x in df_booklet['len']:\n",
    "    sum = sum + x\n",
    "    if sum == 500:\n",
    "        splits.append(counter)\n",
    "        counter = counter + 1\n",
    "        sum = 0\n",
    "    elif sum > 500:\n",
    "        counter = counter + 1\n",
    "        splits.append(counter)\n",
    "        sum = sum - 500\n",
    "    else:\n",
    "        splits.append(counter)\n",
    "\n",
    "\n",
    "df_booklet['group'] = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = df_booklet.groupby('group')['book'].agg(lambda x: list(set(x)))\n",
    "paragraphs = df_booklet.groupby('group')['paragraph'].agg(lambda x: sorted(list(set(x))))\n",
    "groups = list(set(df_booklet.group.values))\n",
    "text = df_booklet.groupby('group')['cleanText'].agg(lambda x: \"\".join(list(x)))\n",
    "\n",
    "df_booklet_new = pd.DataFrame({\"books\": books, \"paragraphs\": paragraphs, \"group\": groups, \"cleanText\":text}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['THIRD EDITION BOOKLET ONE: INTRODUCTION SECTION  DECEMBER 2020 TECHNICAL GUIDELINES FOR INTEGRATED DISEASE SURVEILLANCE AND RESPONSE IN MALAWI THIRD EDITION BOOKLET ONE: INTRODCUTION SECTION This booklet introduces all the eleven modules of the 3rd Edition Malawi Integrated Disease Surveillance and Response Technical Guidelines DECEMBER, 2020 Table of Contents  FOREWORD iv ACKNOWLEDGEMENTS vi LIST OF ABBREVIATIONS vii GLOSSARY (DEFINITION OF KEY TERMS) x 1.1 Introduction 1 ',\n",
       "       '1.2 Public Health Surveillance 1 1.2.1 Definition of the different typesapproaches of public health surveillance 2 1.2.1.1 Indicator-based surveillance 2 1.2.1.2 Event- Based Surveillance (EBS) 5 1.2.3 Event- based surveillance (EBS) and Indicator-Based Surveillance (IBS) as back-bone to the IDSR Strategy 8 1.3 Integrated Disease Surveillance and Response strategy 9 1.3.1 Objectives of Integrated Disease Surveillance and Response 11 1.4 IDSR and IHR (2005) 12 1.4.1 IHR 2005 purpose and goal 12 ',\n",
       "       '1.4.2 Monitoring and evaluating the functional core capacity for implementation of IHR (2005) 14 1.5 One Health and IDSR 15 1.6 IDSR and Disaster Risk Management (DRM) 16 1.7 Implementing Cross Border activities in the context of IDSR 17 1.8 Electronic IDSR (eIDSR) as a platform to enhance real time surveillance 18 1.9 Description of Surveillance functions as described in these guidelines 19 1.9.2 How districts can strengthen surveillance and response 22 ',\n",
       "       '1.10 Efforts of the WHO in the African Region to strengthen IDSR 23 1.11 The contents of the guidelines 24 1.11.1 Key people and entities that will use this guideline 25 1.12 Priority diseases, conditions and events included in the IDSR 26 1.13 Organization of the IDSR guidelines 29 1.14 Annexes for Introduction section 31 Annex A: IDSR matrix: Core functions and activities by health system level 32 Annex B: Tool for assessment of surveillance and response at the district level 39 Annex C: IHR 2005 Decision Instrument 46 ',\n",
       "       'Annex D: Events of potential international health concern requiring reporting to WHO under the International Health Regulations 2005 47 Annex E: Guide for Establishing Community Based Surveillance and response 49 Annex F: Required surveillance and response core capacities as described in the IHR 57 Annex G: Roles and Responsibilities of various actors in IDSR 61 Annex H: Guide for Establishing Surveillance and Response systems at PoE` 68 1.15 References 72 FOREWORD '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_booklet_new.head()['cleanText'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets reformat the paragraphs. If they all appear in the same book we will only report the min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet_new['paragraphs'] = df_booklet_new.apply(lambda row: \",\".join([str(x) for x in row['paragraphs']]) if len(row['books']) > 1 else\n",
    "                                                                str(row['paragraphs'][0]) if (len(row['books']) == 1) and (len(row['paragraphs']) == 1)\n",
    "                                                                else \"-\".join([str(row[\"paragraphs\"][0]), str(row[\"paragraphs\"][-1])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_booklet_new['books'] = df_booklet_new.apply(lambda row: \",\".join(list(set(row['books']))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING DB\n"
     ]
    }
   ],
   "source": [
    "vector_store = embed_booklets(df_booklet_new,recreate_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem like the following steps will have to be taken:\n",
    "\n",
    "- embed booklet\n",
    "- embed search phrase\n",
    "- use search phrase embedding to search for relevant text in booklet\n",
    "- retrive all relevant text from booklet\n",
    "- format search phrase and into prompt for LLM\n",
    "- Send promt to LLM and return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama\n",
    "To use ollama install follow these instructions:\n",
    "\n",
    "- Download and install Ollama onto the available supported platforms (including Windows Subsystem for Linux) (https://ollama.com/)\n",
    "- Fetch available LLM model via ollama pull llama2\n",
    "\n",
    "This will download the default tagged version of the model. Typically, the default points to the latest, smallest sized-parameter model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = Ollama(model=\"phi\", gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(pwd +  \"/data/data/Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_letter(s):\n",
    "    m = re.search(r'[a-z]', s, re.I)\n",
    "    if m is not None:\n",
    "        return m.start()\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_keywords(keywords:str):\n",
    "    keywords_list = keywords.split(\"Keywords:\")[-1].split(',')\n",
    "    if len(keywords_list) == 1:\n",
    "        keywords_list = keywords.split(\"Keywords:\")[-1].split('\\n')\n",
    "    keywords_indexes = [first_letter(word) for word in keywords_list]\n",
    "    clean_keywords = [keywords_list[i][keywords_indexes[i]:] for i in range(len(keywords_list))]\n",
    "    parsed_keywords = \", \".join(list(set([i.lstrip().capitalize().replace('\\n', \"\") for i in clean_keywords])))\n",
    "    return parsed_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_book_info(book_info: dict):\n",
    "    if len(set(book_info['book'].split(\",\"))) > 1:\n",
    "        book_info['book'] = book_info['book'].split(\",\")[0]\n",
    "        book_info['paragraph'] = book_info['paragraph'].split(\",\")[0]\n",
    "\n",
    "    else: \n",
    "        book_info['book'] = book_info['book'].split(\",\")[0]\n",
    "    return book_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = []\n",
    "responses = []\n",
    "for index, row in df_train.head(20).iterrows():\n",
    "    question = row['Question Text']\n",
    "    docs = vector_store.similarity_search_with_score(question, k=2)\n",
    "    booklet_matches = [doc[0].page_content for doc in docs]\n",
    "    response = get_response(text=question, llm=llm_model, booklet_matches=booklet_matches, text_column=\"text\")\n",
    "    keywords = llm_model.generate(f\"Generate keywords form the following text {response['answer']}\")\n",
    "    book_docs = vector_store.similarity_search(response['answer'], k=1)\n",
    "\n",
    "    response[\"book\"] = \"TG Booklet \" + book_docs[0].metadata[\"books\"][-1]\n",
    "    response[\"paragraph\"] = book_docs[0].metadata[\"paragraphs\"]\n",
    "    response['keywords'] = format_keywords(keywords)\n",
    "    responses.append(response)\n",
    "\n",
    "    scores = scorer.score(response['answer'], row['Question Answer'])\n",
    "    rouge_scores.append(scores['rouge1'][-1])\n",
    "    scores = scorer.score(response['keywords'], row['Keywords'])\n",
    "    rouge_scores.append(scores['rouge1'][-1])\n",
    "    scores = scorer.score(response['book'], row['Reference Document'])\n",
    "    rouge_scores.append(scores['rouge1'][-1])\n",
    "    scores = scorer.score(response['paragraph'], row['Paragraph(s) Number'])\n",
    "    rouge_scores.append(scores['rouge1'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question Text</th>\n",
       "      <th>Question Answer</th>\n",
       "      <th>Reference Document</th>\n",
       "      <th>Paragraph(s) Number</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q829</td>\n",
       "      <td>Compare the laboratory confirmation methods fo...</td>\n",
       "      <td>Chikungunya is confirmed using serological tes...</td>\n",
       "      <td>TG Booklet 6</td>\n",
       "      <td>154, 166</td>\n",
       "      <td>Laboratory Confirmation For Chikungunya Vs. Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q721</td>\n",
       "      <td>When should specimens be collected for Anthrax...</td>\n",
       "      <td>Specimens should be collected during the vesic...</td>\n",
       "      <td>TG Booklet 6</td>\n",
       "      <td>140</td>\n",
       "      <td>Anthrax Specimen Collection: Timing, Preparati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q464</td>\n",
       "      <td>Which key information should be recorded durin...</td>\n",
       "      <td>During a register review, key information abou...</td>\n",
       "      <td>TG Booklet 3</td>\n",
       "      <td>439-440</td>\n",
       "      <td>Register Review, Key Information, Suspected Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q449</td>\n",
       "      <td>Why is the District log of suspected outbreaks...</td>\n",
       "      <td>The log includes information about response ac...</td>\n",
       "      <td>TG Booklet 3</td>\n",
       "      <td>412</td>\n",
       "      <td>District Log, Response Activities, Steps Taken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q6</td>\n",
       "      <td>What do Community based surveillance strategie...</td>\n",
       "      <td>Community-based surveillance strategies focus ...</td>\n",
       "      <td>TG Booklet 1</td>\n",
       "      <td>86</td>\n",
       "      <td>Community-based Surveillance Strategies, Ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q451</td>\n",
       "      <td>Compare and contrast the District log of suspe...</td>\n",
       "      <td>The District log (Annex 4A) focuses on recordi...</td>\n",
       "      <td>TG Booklet 3</td>\n",
       "      <td>411, 414</td>\n",
       "      <td>District Log, Laboratory Supplies Checklist, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q337</td>\n",
       "      <td>How can the laboratory results be reviewed dur...</td>\n",
       "      <td>Review laboratory results with the investigati...</td>\n",
       "      <td>TG Booklet 3</td>\n",
       "      <td>294</td>\n",
       "      <td>Laboratory Results Review, Team, Health Facili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q113</td>\n",
       "      <td>How should the One Health approach be implemen...</td>\n",
       "      <td>Emphasize the implementation of the One Health...</td>\n",
       "      <td>TG Booklet 2</td>\n",
       "      <td>652</td>\n",
       "      <td>One Health Approach Implementation, Reporting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q1160</td>\n",
       "      <td>How does the role of a coordinator at the nati...</td>\n",
       "      <td>The national level coordinator provides overar...</td>\n",
       "      <td>TG Booklet 5</td>\n",
       "      <td>128, 137-142</td>\n",
       "      <td>National Level Coordinator, District Level Foc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q188</td>\n",
       "      <td>Can you provide an example of a district spot ...</td>\n",
       "      <td>Yes, Figure 3.6 shows an example of a district...</td>\n",
       "      <td>TG Booklet 2</td>\n",
       "      <td>817</td>\n",
       "      <td>Example Of District Spot Map, Location Of Susp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                      Question Text  \\\n",
       "0   Q829  Compare the laboratory confirmation methods fo...   \n",
       "1   Q721  When should specimens be collected for Anthrax...   \n",
       "2   Q464  Which key information should be recorded durin...   \n",
       "3   Q449  Why is the District log of suspected outbreaks...   \n",
       "4     Q6  What do Community based surveillance strategie...   \n",
       "5   Q451  Compare and contrast the District log of suspe...   \n",
       "6   Q337  How can the laboratory results be reviewed dur...   \n",
       "7   Q113  How should the One Health approach be implemen...   \n",
       "8  Q1160  How does the role of a coordinator at the nati...   \n",
       "9   Q188  Can you provide an example of a district spot ...   \n",
       "\n",
       "                                     Question Answer Reference Document  \\\n",
       "0  Chikungunya is confirmed using serological tes...       TG Booklet 6   \n",
       "1  Specimens should be collected during the vesic...       TG Booklet 6   \n",
       "2  During a register review, key information abou...       TG Booklet 3   \n",
       "3  The log includes information about response ac...       TG Booklet 3   \n",
       "4  Community-based surveillance strategies focus ...       TG Booklet 1   \n",
       "5  The District log (Annex 4A) focuses on recordi...       TG Booklet 3   \n",
       "6  Review laboratory results with the investigati...       TG Booklet 3   \n",
       "7  Emphasize the implementation of the One Health...       TG Booklet 2   \n",
       "8  The national level coordinator provides overar...       TG Booklet 5   \n",
       "9  Yes, Figure 3.6 shows an example of a district...       TG Booklet 2   \n",
       "\n",
       "  Paragraph(s) Number                                           Keywords  \n",
       "0            154, 166  Laboratory Confirmation For Chikungunya Vs. Di...  \n",
       "1                 140  Anthrax Specimen Collection: Timing, Preparati...  \n",
       "2             439-440  Register Review, Key Information, Suspected Ca...  \n",
       "3                 412  District Log, Response Activities, Steps Taken...  \n",
       "4                  86  Community-based Surveillance Strategies, Ident...  \n",
       "5            411, 414  District Log, Laboratory Supplies Checklist, P...  \n",
       "6                 294  Laboratory Results Review, Team, Health Facili...  \n",
       "7                 652  One Health Approach Implementation, Reporting,...  \n",
       "8        128, 137-142  National Level Coordinator, District Level Foc...  \n",
       "9                 817  Example Of District Spot Map, Location Of Susp...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'The laboratory confirmation methods for Chikungunya are based on detecting the presence of the virus in blood samples. Diabetes is diagnosed through blood glucose measurements. Both diseases can be confirmed by laboratory tests, but they have different diagnostic criteria and outcomes. ',\n",
       "  'book': 'TG Booklet 6',\n",
       "  'paragraph': '155',\n",
       "  'keywords': 'Blood samples, Chikungunya, Diagnostic criteria, Diabetes, Blood glucose measurements, Outcomes., Laboratory confirmation'},\n",
       " {'answer': 'Specimens should be collected from any patient being evaluated for cutaneous Bacillus anthracis infection. It may not be possible to demonstrate B.anthracis in clinical specimens if the patient has been treated with antimicrobial agents. Organism is best demonstrated in specimen taken at the vesicular stage. Vesicular stage: collect fluid from intact vesicles on sterile swabs. Eschar stage: without removing eschar, insert swab beneath the edge of eschar, rotate and collect lesion material. Store specimen for 24 h and transport for 2h at room temperature. Stool: collect 5-10 g in a clean sterile leak-proof container. Store for 24 h at 4 C. Transport 1h at room temperature. Blood: collect per institution s procedure for routine blood culture. Collect 10 ml of blood in EDTA tube for PCR. Transport 2h at room temperature. Sputum: collect expectorated specimen into a sterile leak proof container. Store for 24 h at 4 C. Transport 2 h at room temperature. Results Diagnostic services for Anthrax are not routinely available. Advance arrangements are usually required for Anthrax diagnostic services. Contact the appropriate National authority or WHO. ',\n",
       "  'book': 'TG Booklet 6',\n",
       "  'paragraph': '140',\n",
       "  'keywords': 'Cutaneous infection, Bacillus anthracis, Vesicular stage, Sputum, Antimicrobial agents, Diagnostic services, Stool, National authority, Eschar stage, Who., Blood'},\n",
       " {'answer': 'During a register review about suspected cases, key information such as age, gender, location, and symptoms should be recorded. This information is utilized in subsequent investigation activities to determine what caused the outbreak or increase in number of cases. The collected data can help identify patterns and trends that may indicate an infectious disease outbreak. Additionally, geo-mapping coordinates can provide valuable insights into the geographic distribution of cases. ',\n",
       "  'book': 'TG Booklet 3',\n",
       "  'paragraph': '311',\n",
       "  'keywords': 'Symptoms, Register review, Gender, Location, Geo-mapping coordinates., Suspected cases, Trends, Investigation activities, Patterns, Age, Infectious disease outbreak'},\n",
       " {'answer': 'The District log of suspected outbreaks and alerts is designed to include information about response activities and steps taken during an outbreak to ensure that appropriate supplies are available for responding to a confirmed case or outbreak. This includes immunization supplies and vaccine, ORS, antibiotics, and other necessary resources. Additionally, the log helps track the progress of response efforts and identify areas where improvements can be made. ',\n",
       "  'book': 'TG Booklet 3',\n",
       "  'paragraph': '412',\n",
       "  'keywords': 'Alerts, Suspected outbreaks, Confirmed cases, Outbreak, Progress tracking, Vaccines, Necessary resources, Steps taken, Ors, Response activities, Antibiotics, Improvement identification., Immunization supplies'},\n",
       " {'answer': 'Community-based surveillance strategies focus on detecting, reporting, and responding to outbreaks of diseases in a timely manner. Indicator-based surveillance is one of the common methods used for this purpose. It involves monitoring specific indicators such as disease symptoms, laboratory results, or environmental factors that can help identify potential outbreaks. By using these principles, communities can work together with health authorities to prevent the spread of diseases and protect public health. ',\n",
       "  'book': 'TG Booklet 1',\n",
       "  'paragraph': '78',\n",
       "  'keywords': 'Reporting, Environmental factors, Prevention, Responding, Outbreak detection, Timely manner, Disease symptoms, Indicator-based surveillance, Community-based surveillance, Laboratory results, Public health.'},\n",
       " {'answer': 'The District log of suspected outbreaks and alerts is a record of any potential disease outbreak or public health emergency that has been reported by health facilities in the district. It contains information such as the date, location, type, number, and status of the cases, as well as the actions taken to contain and investigate them. The laboratory supplies checklist is a list of the equipment, reagents, and materials needed for conducting laboratory tests for confirmation of diseases from the suspected outbreaks and alerts. It helps to ensure that the laboratories have adequate and appropriate resources to perform their functions effectively and safely. Both documents serve different purposes in the public health system: the log helps to monitor and respond to potential threats, while the checklist helps to support and facilitate the laboratory testing process. ',\n",
       "  'book': 'TG Booklet 3',\n",
       "  'paragraph': '414',\n",
       "  'keywords': 'Keywords from the text:- district log of suspected outbreaks and alerts- disease outbreak or public health emergency- health facilities- date, Materials- confirmation of diseases- public health system- support- facilitate- monitor and respond to potential threats- ensure adequate and appropriate resources- perform functions effectively and safely. , Location, Reagents, Cases- actions taken- laboratory tests- equipment, Status, Type, Number'},\n",
       " {'answer': 'Laboratory results can be reviewed during an outbreak investigation by following established protocols and procedures set by the National Reference Labs (NRLs). These labs may act as first contact labs or referral labs, depending on the nature of the outbreak. The NRLs should distribute appropriate specimen collection kits for epidemic-prone diseases to health facilities and providers. They should also request additional specimens to be collected if necessary. Specimens should be stored within approved conditions for further referral and analysis or additional research or investigation. Confirmation policies and procedures should be set with the NRLs, and laboratory studies performed for confirmation as appropriate. Representative isolates from the outbreak should be stored for future reference. Laboratory results should be recorded, stored, and backed up regularly. The NRLs should report their findings to the District Rapid Response Team (DRRT) and all relevant stakeholders at the national and district levels. Case-based and summary data should also be reported according to agreed protocols. Routine analysis of laboratory analysis, data, and results should be carried out to identify any changes in trends. If necessary, additional studies may be recommended for controlling the situation further. The NRLs should immediately prepare an outbreak investigation report that is disseminated to all relevant parties. ',\n",
       "  'book': 'TG Booklet 2',\n",
       "  'paragraph': '422',\n",
       "  'keywords': 'Additional studies, Outbreak investigation, National reference labs (nrls), Confirmation policies and procedures, Specimen collection kits, Case-based and summary data, Routine analysis, Outbreak investigation report., Laboratory results, District rapid response team (drrt)'},\n",
       " {'answer': 'The One Health approach should be implemented by promoting a multi-sectoral approach that involves human, animal, and environmental health sectors as well as other relevant sectors. This approach aims at strengthening reporting of public health risks across all levels, with emphasis also at the community level. It requires collaboration between different sectors to detect events which might have an impact on the health of humans and their shared environment. Strengthening technical and community capacities is essential for effective implementation of this approach. ',\n",
       "  'book': 'TG Booklet 2',\n",
       "  'paragraph': '162',\n",
       "  'keywords': 'Community level, Technical and community capacities, Relevant sectors, Human, Multi-sectoral approach, Impact on health, Environmental health sectors, Effective implementation., Detection, Collaboration, One health approach, Public health risks, Different sectors, Animal, Shared environment'},\n",
       " {'answer': 'The role of a coordinator at the national level is more focused on aggregating data from different districts, analyzing trends and making conclusions about priority diseases, conditions, and events. On the other hand, district-level focal points are responsible for verifying alerts from the community, collecting surveillance data from health facilities and the community, ensuring reliable supply of data collection tools, and providing instructions and supervision to health facility and community volunteers on reporting priority diseases, conditions, and events. ',\n",
       "  'book': 'TG Booklet 1',\n",
       "  'paragraph': '108',\n",
       "  'keywords': 'Community volunteers, Making conclusions, And events., Reporting priority diseases, District-level focal points, Health facilities, Verifying alerts, National level, Coordinator, Analyzing trends, Reliable supply, Conditions, Aggregating data, Collecting surveillance data'},\n",
       " {'answer': 'Sure! In Malawian public health, we use district spot maps to track the spread of diseases in specific areas. These maps show where suspected and confirmed cases have been reported, allowing us to identify hotspots and take action to prevent further transmission. For example, if a particular area has a high concentration of cases, we may increase surveillance efforts there or implement targeted interventions such as vaccination campaigns. ',\n",
       "  'book': 'TG Booklet 2',\n",
       "  'paragraph': '815',\n",
       "  'keywords': 'Hotspots, Track spread of diseases, Suspected and confirmed cases, Take action to prevent further transmission, Specific areas, Malawian public health, Vaccination campaigns., District spot maps'},\n",
       " {'answer': 'The common methods of indicator-based surveillance include monitoring disease incidence, prevalence, and mortality rates; tracking laboratory test results; and analyzing demographic data. These indicators can be used to monitor the quality of the surveillance system by identifying trends in disease occurrence and assessing the effectiveness of public health interventions. However, it is important to note that there are many other attributes that contribute to a comprehensive evaluation of a surveillance system, such as timeliness, completeness, and accuracy of data collection. ',\n",
       "  'book': 'TG Booklet 4',\n",
       "  'paragraph': '137',\n",
       "  'keywords': 'Completeness, Prevalence, Monitoring disease incidence, Quality of the surveillance system, Accuracy of data collection., Analyzing demographic data, Effectiveness of public health interventions, Indicator-based surveillance, Tracking laboratory test results, Trends in disease occurrence, Timeliness, And mortality rates'},\n",
       " {'answer': 'The timeliness of reporting can be monitored and assessed at the district level by routinely recording and reviewing the dates on which reports are received, measuring how many reporting units submitted reports for a given week month against the number of units expected to report, identifying which reporting units have reported, and defining how often the required data should be reported. A monitoring tool such as the one in Annex 8F can also be used to monitor timeliness in your district. ',\n",
       "  'book': 'TG Booklet 4',\n",
       "  'paragraph': '222-224',\n",
       "  'keywords': 'Received, Data, Reporting, Units, Monitoring, Identifying, Dates, Recording, Reports, Submitting, Tool, Annex 8f., District level, Expected, Reviewing, Measuring, Timeliness'},\n",
       " {'answer': 'The responsibilities of public and partner-supported health facilities or clinics differ from those at the central/national level in crisis situations. At the district level, there is a focus on verifying alerts from the community, collecting surveillance data from both the facility and the community, reviewing the quality of data collection and reporting tools, ensuring reliable supply of materials for laboratory collection and transport, providing instructions and supervision for surveillance and reporting priority diseases, conditions, and events, maintaining a list of reporting sites, and assisting health facilities in updating graphs, tables, and charts to describe reported cases. Additionally, there is an emphasis on integrating epidemiological and laboratory data for better analysis, comparing data to identify trends and thresholds, supporting health facilities with safe collection, packaging, storage, and transport of laboratory specimens, receiving laboratory results from reference laboratories, reporting findings of initial investigations to the national level, establishing and ensuring functionality of emergency preparedness and response committees, participating in risk mapping and community assessments, organizing training for health facilities and communities, and documenting response activities. ',\n",
       "  'book': 'TG Booklet 1',\n",
       "  'paragraph': '309',\n",
       "  'keywords': 'Maintaining reporting sites, Safe collection, Storage, Community assessments, Events, Emergency preparedness, Assisting with updates, Reliable supply of materials, Packaging, Partner-supported clinics, Instructions and supervision, Analyzing trends, Integrating data, Transport, Reporting findings, Response committees, District level, Risk mapping, Receiving laboratory results, Collecting surveillance data, Priority diseases, Reviewing quality of tools, Public health facilities, Verifying alerts, Crisis situations, Conditions, Documenting activities., Training, Supporting health facilities'},\n",
       " {'answer': 'The Ministry of Security could be crucial in enforcing control measures by law during an outbreak. Their involvement is important because they can help ensure that there are adequate resources and personnel available to enforce the necessary restrictions, such as curfews or travel bans. Additionally, they may have expertise in dealing with potential security threats that could arise during an outbreak, which could be critical for maintaining public safety. ',\n",
       "  'book': 'TG Booklet 3',\n",
       "  'paragraph': '379',\n",
       "  'keywords': 'Personnel, Travel bans, Public safety, Outbreak, Security threats., Resources, Law, Curfews, Ministry of security, Enforcing control measures'},\n",
       " {'answer': 'A register review is conducted to collect data on admitted patients at a health facility during a specific period, while the District log of suspected outbreaks and alerts is used to track potential disease outbreaks or increases in cases. The purpose of both is to identify the cause of an outbreak or increase in cases, but the criteria for conducting a register review are more specific, requiring that the facility have more than 10 hospital beds. ',\n",
       "  'book': 'TG Booklet 3',\n",
       "  'paragraph': '421-422',\n",
       "  'keywords': 'Alerts, Suspected outbreaks, Health facility, Register review, Specific criteria, Data collection, Disease outbreaks, Increases in cases, Identify cause, More than 10 hospital beds., Admitted patients'},\n",
       " {'answer': 'It is important to estimate carrier numbers for viral hepatitis B and C because it helps us understand the prevalence of these diseases in a population, which can inform public health interventions such as vaccination campaigns and targeted screening programs. Additionally, estimating the burden of chronic viral hepatitis can help identify areas where treatment and care services are needed most. ',\n",
       "  'book': 'TG Booklet 6',\n",
       "  'paragraph': '127',\n",
       "  'keywords': 'Targeted screening programs, Need., Prevalence, Carrier numbers, Viral hepatitis b and c, Public health interventions, Treatment and care services, Vaccination campaigns, Burden of chronic viral hepatitis'},\n",
       " {'answer': 'Large outbreaks of bacterial meningitis typically occur in the meningitis belt, which is a region that stretches across sub-Saharan Africa. These outbreaks are characterized by high numbers of cases and can have severe consequences due to limited access to healthcare resources. In contrast, smaller outbreaks outside the meningitis belt may be less frequent but still pose a risk, especially in areas with poor sanitation or overcrowded living conditions. ',\n",
       "  'book': 'TG Booklet 6',\n",
       "  'paragraph': '143',\n",
       "  'keywords': 'High numbers of cases, Smaller outbreaks, Bacterial meningitis, Overcrowded living conditions., Poor sanitation, Sub-saharan africa, Severe consequences, Meningitis belt, Limited access to healthcare resources, Outbreaks'},\n",
       " {'answer': 'Implementing IDSR in humanitarian emergencies involves enhancing IDSR core functions to ensure early detection, assessment, and response to acute public health events. The system set up should be based on the IDSR strategy, structures, tools, guidelines, and resources while ensuring flexibility required in addressing the surveillance and response needs of affected populations in emergency situations. This should be done within the existing national IDSR system. ',\n",
       "  'book': 'TG Booklet 5',\n",
       "  'paragraph': '85-86',\n",
       "  'keywords': 'Idsr core functions, Guidelines, Response, Assessment, Acute public health events, National idsr system., Humanitarian emergencies, Resources, Strategy, Structures, Flexibility, Implementing idsr, Tools, Early detection'},\n",
       " {'answer': \"It's important to have and maintain a logbook of rumors because it helps in tracking reported outbreaks, events, and alerts to confirm or dispel rumors. This allows for timely action and resolution of suspected outbreaks, ensuring that each report is followed by some form of action. Keeping this record also provides valuable information for evaluating the timeliness and completeness of the outbreak investigation and response process. \",\n",
       "  'book': 'TG Booklet 1',\n",
       "  'paragraph': '331',\n",
       "  'keywords': 'Alerts, Timely action, Suspected outbreaks, Response process., Completeness, Outbreak investigation, Tracking, Confirm or dispel, Logbook, Events, Reported outbreaks, Rumors, Evaluation, Resolution, Timeliness'},\n",
       " {'answer': 'The criteria for prioritizing health problems during the emergency phase are based on WHO guidelines for inclusion of an event under a surveillance system. These include diseases that pose a threat to the population, such as epidemic, vaccine-preventable diseases due to disruption of immunization, and those with the ability to cause severe morbidity or death. The criteria also take into account international surveillance requirements, availability of prevention and control measures, and reliable case definitions and simple laboratory tests. ',\n",
       "  'book': 'TG Booklet 5',\n",
       "  'paragraph': '150-156',\n",
       "  'keywords': 'Surveillance system, International requirements, Emergency phase, Prevention and control measures, Vaccine-preventable diseases, Mortality, Morbidity, Case definitions, Population health, Disease threat, Who guidelines, Laboratory tests., Immunization'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4724537893321026"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rouge_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(pwd +  \"/data/data/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(columns=['answer', 'book', 'paragraphs', 'keywords', 'ID', 'Question'])\n",
    "df_submission.to_csv(pwd + \"/data/submissions/submission_v8_temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "responses = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    id = row['ID']\n",
    "    question = row['Question Text']\n",
    "    docs = vector_store.similarity_search_with_score(question, k=3)\n",
    "    booklet_matches = [doc[0].page_content for doc in docs]\n",
    "    response = get_response(text=question, llm=llm_model, booklet_matches=booklet_matches, text_column=\"text\")\n",
    "    keywords = llm_model.generate(f\"Generate keywords form the following text {response['answer']}\")\n",
    "    book_docs = vector_store.similarity_search(response['answer'], k=1)\n",
    "\n",
    "    response[\"book\"] = \"TG Booklet \" + book_docs[0].metadata[\"books\"][-1]\n",
    "    response[\"paragraph\"] = book_docs[0].metadata[\"paragraphs\"]\n",
    "    response['keywords'] = format_keywords(keywords)\n",
    "    df_responses = pd.DataFrame([response])\n",
    "    df_responses['ID'] = id\n",
    "    df_responses['Question'] = question\n",
    "    csv_file_path = pwd + \"/data/submissions/submission_v8_temp.csv\"\n",
    "    df_responses[['answer', 'book', 'paragraph', 'keywords', 'ID', 'Question']].to_csv(csv_file_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses = pd.read_csv(pwd +  \"/data/submissions/submission_v8_temp.csv\")\n",
    "df_responses.columns = ['answer', 'book', 'paragraphs', 'keywords', 'ID', 'Question', 'None']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submissoion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses.drop(['None'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses.columns = ['question_answer', 'reference_document', 'paragraph(s)_number', 'keywords', 'ID', 'Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.melt(df_responses, id_vars=['ID'], value_vars=['question_answer', 'reference_document', 'paragraph(s)_number', \"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['ID'] = df_submission['ID'] + '_' + df_submission['variable']\n",
    "df_submission.columns = [\"ID\", \"variable\", \"Target\"]\n",
    "df_submission = df_submission[['ID', \"Target\"]].set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(pwd + \"/data/submissions/submission_v8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 ('zindi_llm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1b94373ed21143aa54ae29a501b4c41cca272fcc00b21ffb9f53282b803de8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
